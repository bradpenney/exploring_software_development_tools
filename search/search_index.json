{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Exploring Software Development Tools","text":"<p>Remove tool friction. Work faster. Keep platforms running.</p> <p></p> <p>Welcome to a practical guide for SREs and Platform Engineers who need to master the tools that make infrastructure work scale.</p>"},{"location":"#the-problem","title":"The Problem","text":"<p>It's 2am. The API is down. You SSH into the server, and suddenly you're fighting your tools instead of fixing the problem. You're parsing JSON by squinting at your terminal. Your SSH connection drops and you lose your work. You're typing the same 15 commands for the hundredth time this week.</p> <p>This is tool friction. This site exists to remove it.</p>"},{"location":"#the-solution","title":"The Solution","text":"<p>While Exploring Linux, Exploring Python, and Exploring Kubernetes teach what to do, this site teaches how to do it efficiently. Master these tools and you'll:</p> <ul> <li>Save 10+ hours per week on repetitive tasks</li> <li>Debug incidents faster with proper tooling</li> <li>Stop losing work to dropped SSH connections</li> <li>Parse JSON/YAML without squinting</li> <li>Edit configs on remote servers without pain</li> </ul>"},{"location":"#how-its-organized","title":"How It's Organized","text":"<p>Content is structured by urgency and job context:</p> <ul> <li> <p> \ud83d\udce6 Essentials</p> <p>Core tools you need today. Can't do the job without these. Each tool has a series of articles.</p> <p>Git Series:</p> <ul> <li>Git Basics - Your first repository, three states, local version control</li> <li>Git Collaboration - Remote repos, GitHub/GitLab, teamwork</li> <li>Git Safety (coming soon) - .gitignore, secrets, undo commands</li> <li>Git Configuration (coming soon) - Aliases, editor setup, advanced config</li> </ul> <p>JQ Series: (coming soon)</p> <p>YQ Series: (coming soon) - YQ - Wrangle YAML configs for K8s/Ansible (coming soon)</p> <p>Vim Series: (coming soon) - Vim Survival Mode - Edit on servers (coming soon)</p> </li> <li> <p> \u26a1 Efficiency</p> <p>Make your day 10x easier. Tools that transform how you work.</p> <ul> <li>Terminal Multiplexing (<code>tmux</code>) - Persistent SSH sessions</li> <li>VS Code Remote - Edit on servers comfortably</li> <li>Shell Productivity (<code>fzf</code>, aliases) - Save hours typing</li> <li>Git Workflows - Branches and conflict resolution</li> </ul> </li> <li> <p> \ud83c\udfaf Mastery</p> <p>Optional power tools. For when you need maximum efficiency.</p> <ul> <li>NeoVim Full Setup - Terminal IDE for remote work</li> <li>Advanced Shell - Custom functions, automation</li> <li>Automation Patterns - Makefiles, pre-commit hooks</li> <li>GitHub Actions - Infrastructure CI/CD</li> </ul> </li> </ul>"},{"location":"#who-this-is-for","title":"Who This Is For","text":"<p>You're an SRE or Platform Engineer who:</p> <ul> <li>Responds to incidents (on-call rotations, debugging under pressure)</li> <li>Manages infrastructure as code (Terraform, Ansible, K8s manifests)</li> <li>Works primarily in terminal environments (SSH, remote servers)</li> <li>Needs to parse JSON/YAML constantly (APIs, kubectl output, logs)</li> <li>Wants to automate repetitive tasks</li> </ul> <p>You may or may not have a traditional developer background. This site meets you where you are.</p>"},{"location":"#integration-with-other-sites","title":"Integration with Other Sites","text":"<p>This site is part of the BradPenney.io learning ecosystem:</p> <ul> <li>Exploring Linux - Linux commands and system administration</li> <li>Exploring Kubernetes - Kubernetes for platform engineers</li> <li>Exploring Python - Python automation and scripting</li> <li>Exploring Computer Science - Computer science fundamentals</li> </ul> <p>How they connect:</p> <ul> <li>Linux site + Tools site = Terminal mastery</li> <li>Python site + Tools site = Automation capability</li> <li>Kubernetes site + Tools site = Platform debugging skills</li> </ul> <p>Ready to remove tool friction? Start with Git Basics - the first article in the Git Essentials series - to professionalize your scripts and infrastructure code.</p>"},{"location":"efficiency/direnv/","title":"Managing Environments with direnv","text":"<p>You're working on three different projects. Project A needs <code>AWS_PROFILE=prod</code>, Project B needs <code>KUBECONFIG=~/.kube/dev-config</code>, and Project C requires a specific API key. You constantly forget to switch your variables, leading to \"oops\" commits or failed commands. This is why you need <code>direnv</code>.</p> <p><code>direnv</code> is an extension for your shell that loads and unloads environment variables depending on your current directory. It allows you to define project-specific environments that \"just work\" the moment you <code>cd</code> into a folder.</p>"},{"location":"efficiency/direnv/#quick-start-the-30-second-setup","title":"Quick Start: The 30-Second Setup","text":"<ol> <li>Install: <code>brew install direnv</code> (or your package manager of choice).</li> <li>Hook: Add <code>eval \"$(direnv hook zsh)\"</code> (or bash) to your shell config.</li> <li>Use: <ul> <li>Go to your project: <code>cd my-project</code></li> <li>Create an environment file: <code>echo \"export AWS_PROFILE=staging\" &gt; .envrc</code></li> <li>Allow it: <code>direnv allow</code></li> </ul> </li> </ol>"},{"location":"efficiency/direnv/#how-direnv-works","title":"How Direnv Works","text":"<p><code>direnv</code> checks for a <code>.envrc</code> file every time your shell prompt appears. If it finds one, it loads the variables. When you <code>cd</code> out of that directory, it automatically unloads them, keeping your shell environment clean.</p> <pre><code>graph LR\n    Home[~] -- \"cd project\" --&gt; Project[project/]\n    Project -- \"loads\" --&gt; Env[.envrc]\n    Env --&gt; Shell[Shell with project variables]\n    Shell -- \"cd ..\" --&gt; Home\n    Home -- \"unloads\" --&gt; Clean[Shell is clean again]</code></pre>"},{"location":"efficiency/direnv/#why-direnv-matters-for-platform-work","title":"Why Direnv Matters for Platform Work","text":"<p>SREs handle multiple contexts\u2014staging, production, different cloud accounts, and local clusters. Manual context switching is a major source of human error. <code>direnv</code> automates the context, reducing the risk of running a production command in a staging environment.</p>"},{"location":"efficiency/direnv/#common-scenarios","title":"Common Scenarios","text":"Cloud Profiles Kubeconfig Isolation Python Virtual Environments <p>Ensure you are always using the correct AWS profile for the infrastructure code you are editing: .envrc<pre><code>export AWS_PROFILE=platform-dev\nexport AWS_REGION=us-east-1\n</code></pre></p> <p>Avoid accidentally running <code>kubectl delete</code> on the wrong cluster: .envrc<pre><code>export KUBECONFIG=$(expand_path ./kubeconfig.yaml)\n</code></pre></p> <p>Automatically activate your <code>venv</code> when you enter the project directory: .envrc<pre><code>layout python3  # Built-in shortcut to find/create a venv\n</code></pre></p>"},{"location":"efficiency/direnv/#best-practices-and-security","title":"Best Practices and Security","text":"<ul> <li> <p> Never Commit <code>.envrc</code></p> <p>Why it matters: <code>.envrc</code> often contains secrets or local paths. Always add it to your <code>.gitignore</code>.</p> </li> <li> <p> The <code>.env</code> Pattern</p> <p>Why it matters: If you already use <code>.env</code> files for Docker, you can load them into <code>direnv</code>: <code>dotenv</code> (inside your <code>.envrc</code>).</p> </li> <li> <p> Explicit Approval</p> <p>Why it matters: <code>direnv</code> won't run a new or changed <code>.envrc</code> until you run <code>direnv allow</code>. This prevents malicious scripts from running automatically when you clone a repo.</p> </li> </ul>"},{"location":"efficiency/direnv/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Unloading Variables <p>You have <code>export FOO=bar</code> in your <code>project/.envrc</code>. You <code>cd</code> into <code>project/</code>, and <code>echo $FOO</code> prints <code>bar</code>. You then <code>cd ..</code>. What does <code>echo $FOO</code> print now?</p> Answer <p>It will print nothing (or whatever the value of <code>$FOO</code> was before you entered the directory). <code>direnv</code> takes a snapshot of your environment before loading and restores it exactly when you leave.</p> Practice Problem 2: Security <p>Why does <code>direnv</code> require you to run <code>direnv allow</code> after every change to a <code>.envrc</code> file?</p> Answer <p>This is a security feature to prevent unauthorized code execution. Since <code>.envrc</code> is a shell script, someone could theoretically send you a project with a <code>.envrc</code> that runs <code>rm -rf /</code>. By requiring manual approval for every change, <code>direnv</code> ensures you have the opportunity to inspect the file.</p>"},{"location":"efficiency/direnv/#key-takeaways","title":"Key Takeaways","text":"Command Action <code>direnv allow</code> Authorize the <code>.envrc</code> in the current dir <code>direnv deny</code> Revoke authorization <code>direnv edit .</code> Open the <code>.envrc</code> in your <code>$EDITOR</code> <code>layout &lt;type&gt;</code> Use built-in templates (python, ruby, go) <code>dotenv</code> Load standard <code>.env</code> files"},{"location":"efficiency/direnv/#further-reading","title":"Further Reading","text":""},{"location":"efficiency/direnv/#official-documentation","title":"Official Documentation","text":"<ul> <li>Direnv.net - Official website and documentation.</li> <li>Direnv Wiki - Community recipes and advanced usage.</li> </ul>"},{"location":"efficiency/direnv/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Autoenv - A simpler, bash-only alternative.</li> <li>Shadowenv - Shopify's take on directory-local environments.</li> </ul>"},{"location":"efficiency/direnv/#deep-dives","title":"Deep Dives","text":"<ul> <li>Process Environments - How Unix processes inherit and manage environment variables.</li> <li>Shell Hooks - How <code>direnv</code> uses the <code>$PROMPT_COMMAND</code> or <code>precmd</code> to trigger its checks.</li> </ul>"},{"location":"efficiency/fzf_advanced/","title":"FZF Mastery: The Interactive Glue","text":"<p>You've used <code>fzf</code> for basic history searching (<code>Ctrl+r</code>). But <code>fzf</code> is more than a history tool; it is a universal interactive filter. It is the \"glue\" that allows you to turn static lists into interactive workflows. This is how you build your own custom CLI interfaces.</p> <p><code>fzf</code> takes any list of text, lets you filter it in real-time, and outputs your selection. This simple primitive can be combined with almost any other tool to create powerful, custom workflows.</p>"},{"location":"efficiency/fzf_advanced/#the-core-concept-input-filter-output","title":"The Core Concept: Input \u2192 Filter \u2192 Output","text":"<pre><code>graph LR\n    List[Any List: files, pods, commits] -- \"pipe |\" --&gt; FZF[fzf]\n    FZF -- \"selection\" --&gt; Command[Next Command]</code></pre>"},{"location":"efficiency/fzf_advanced/#quick-start-the-one-liners","title":"Quick Start: The One-Liners","text":"<p>Add these to your aliases for immediate impact:</p> FZF Multipliers<pre><code># Select a file and open it in your editor\nalias fo='fd --type f | fzf | xargs -r ${EDITOR:-vim}'\n\n# Select a process to kill\nalias pk='ps -ef | fzf --header-line=1 | awk \"{print \\$2}\" | xargs kill -9'\n\n# Select a git branch to checkout\nalias gc='git branch | fzf | xargs git checkout'\n</code></pre>"},{"location":"efficiency/fzf_advanced/#why-fzf-matters-for-platform-work","title":"Why FZF Matters for Platform Work","text":"<p>SREs spend their time navigating complex namespaces and large numbers of resources. <code>fzf</code> allows you to navigate these without having to memorize names or copy-paste from the terminal.</p>"},{"location":"efficiency/fzf_advanced/#common-scenarios","title":"Common Scenarios","text":"Interactive Pod Logs Cleaning Up Containers Searching JSON with fzf <p>Stop typing pod names manually. Select from a live list: Interactive Logs<pre><code>kl() {\n  kubectl logs -f $(kubectl get pods -o name | fzf --prompt=\"Pod &gt; \")\n}\n</code></pre></p> <p>Select multiple containers to stop and remove at once: Bulk Cleanup<pre><code>dc() {\n  docker ps -a --format '{{.ID}}    {{.Names}}  {{.Status}}' | \n  fzf --multi --header-line=0 | awk '{print $1}' | xargs docker rm -f\n}\n</code></pre></p> <p>Use <code>fzf</code> to explore large JSON files interactively (requires <code>jq</code>): JSON Browser<pre><code># Select a key from a JSON object\ncat config.json | jq -r 'keys[]' | fzf | xargs -I {} jq '.{}' config.json\n</code></pre></p>"},{"location":"efficiency/fzf_advanced/#advanced-fzf-features","title":"Advanced FZF Features","text":"<ul> <li> <p> The Preview Window</p> <p>Why it matters: See the contents of a file or the details of a resource before you select it.</p> <p><code>fzf --preview 'bat --color=always {}'</code></p> </li> <li> <p> Multi-Select (<code>-m</code>)</p> <p>Why it matters: Select multiple items using <code>Tab</code>. Perfect for bulk operations like deleting files or stopping services.</p> </li> <li> <p> Custom Bindings</p> <p>Why it matters: Bind keys within <code>fzf</code> to perform actions. <code>--bind 'ctrl-e:execute(vim {})'</code></p> </li> </ul>"},{"location":"efficiency/fzf_advanced/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Previews <p>How would you create an <code>fzf</code> command that lists all files in the current directory and shows a preview of the first 10 lines of each file as you move through the list?</p> Answer <pre><code>fzf --preview 'head -n 10 {}'\n</code></pre> Practice Problem 2: Extraction <p>When you pipe <code>ps -ef</code> into <code>fzf</code>, the output contains many columns. How do you extract just the PID (the second column) of the selected line?</p> Answer <p><pre><code>ps -ef | fzf | awk '{print $2}'\n</code></pre> <code>awk</code> is the perfect partner for <code>fzf</code> when you need to extract specific fields from a structured line of text.</p>"},{"location":"efficiency/fzf_advanced/#key-takeaways","title":"Key Takeaways","text":"Feature Flag Purpose Multi-select <code>-m</code> or <code>--multi</code> Select multiple items with <code>Tab</code> Preview <code>--preview 'cmd'</code> Run a command on the current item Prompt <code>--prompt 'text'</code> Change the input prompt Header <code>--header 'text'</code> Add a static header at the top Exact Match <code>-e</code> Use exact matching instead of fuzzy"},{"location":"efficiency/fzf_advanced/#further-reading","title":"Further Reading","text":""},{"location":"efficiency/fzf_advanced/#official-documentation","title":"Official Documentation","text":"<ul> <li>fzf Wiki: Examples - A treasure trove of community-built functions.</li> <li>fzf Manual - Detailed reference for all flags and bindings.</li> </ul>"},{"location":"efficiency/fzf_advanced/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Skim - A similar fuzzy finder written in Rust.</li> <li>Peco - Another interactive filtering tool.</li> </ul>"},{"location":"efficiency/fzf_advanced/#deep-dives","title":"Deep Dives","text":"<ul> <li>Pipes and Filters - The core Unix philosophy that makes <code>fzf</code> so powerful.</li> <li>Human-Computer Interaction - Why interactive filtering is faster than manual command typing.</li> </ul>"},{"location":"efficiency/git_workflows/","title":"Git Workflows for Infrastructure","text":"<p>You've made a change to a Terraform module in your feature branch. Meanwhile, a colleague merged a change to the same file in <code>main</code>. Now you have a merge conflict in a 500-line YAML file. This is where a solid workflow saves your day.</p> <p>In Platform Engineering, we don't just use Git to save code; we use it to coordinate changes to live environments. A structured workflow ensures that infrastructure changes are reviewed, tested, and deployed without causing outages.</p>"},{"location":"efficiency/git_workflows/#the-feature-branch-workflow-iac-edition","title":"The Feature Branch Workflow (IaC Edition)","text":"<p>This is the industry standard for managing infrastructure changes. It prioritizes peer review and automated testing (CI) before any change touches production.</p> <pre><code>graph LR\n    Main[main branch] -- \"git checkout -b\" --&gt; Feature[feature/fix-lb-rule]\n    Feature -- \"git commit\" --&gt; Feature\n    Feature -- \"PR / Plan\" --&gt; Review{Peer Review}\n    Review -- \"Approve\" --&gt; Main\n    Main -- \"CD / Apply\" --&gt; Prod((Production))</code></pre>"},{"location":"efficiency/git_workflows/#quick-start-the-5-step-workflow","title":"Quick Start: The 5-Step Workflow","text":"<ol> <li>Sync: <code>git checkout main &amp;&amp; git pull origin main</code></li> <li>Branch: <code>git checkout -b feat/add-logging</code></li> <li>Work: Make changes, <code>git add</code>, and <code>git commit -m \"feat: add logging to api\"</code></li> <li>Update: <code>git fetch origin main &amp;&amp; git rebase origin/main</code> (Keep your branch up to date)</li> <li>Push: <code>git push origin feat/add-logging</code> and open a Pull Request.</li> </ol>"},{"location":"efficiency/git_workflows/#why-workflows-matter-for-platform-work","title":"Why Workflows Matter for Platform Work","text":"<p>A bad Git workflow in application dev might delay a feature. A bad Git workflow in platform engineering can take down an entire region.</p>"},{"location":"efficiency/git_workflows/#common-scenarios","title":"Common Scenarios","text":"Resolving YAML Conflicts Linear History with Rebasing Atomic Infrastructure Commits <p>YAML is whitespace-sensitive. When Git shows a conflict, it can be hard to see where the indentation broke. - Use a visual merge tool or VS Code's conflict resolution UI. - Always run <code>yq</code> or a linter on the file after resolving a conflict to ensure the syntax is still valid. - <code>yq eval '.' config.yaml</code> (If this fails, your resolution is broken).</p> <p>Platform teams often prefer <code>rebase</code> over <code>merge</code> for feature branches. This keeps the history linear and makes it easier to track when a specific infrastructure change was introduced. - <code>git rebase main</code> moves your changes to the \"tip\" of the current main branch. - It avoids \"Merge branch 'main' into feature\" noise in your logs.</p> <p>Each commit should represent a single, logical change to the infrastructure. - Bad: <code>git commit -m \"updated stuff\"</code> (Changes firewall, DNS, and IAM in one go). - Good: <code>git commit -m \"feat: add egress rule for database\"</code> (Focused and easy to revert).</p>"},{"location":"efficiency/git_workflows/#core-workflow-patterns","title":"Core Workflow Patterns","text":"<ul> <li> <p> Pull Request (PR) Culture</p> <p>Why it matters: PRs aren't just for code review; they are for \"Plan\" review. Attach your <code>terraform plan</code> or <code>kustomize build</code> output to the PR.</p> </li> <li> <p> Protected Branches</p> <p>Why it matters: Ensure that no one can push directly to <code>main</code>. Require at least one approval and passing CI checks (linting, security scans).</p> </li> <li> <p> Revert Strategy</p> <p>Why it matters: If an infrastructure change causes an incident, the fastest way back is often <code>git revert</code>. Practice this before you need it.</p> </li> </ul>"},{"location":"efficiency/git_workflows/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Rebase vs Merge <p>You are on a feature branch and <code>main</code> has moved forward. You want to incorporate those changes while keeping your own commits at the top of the history. Which command do you use?</p> Answer <p><pre><code>git fetch origin\ngit rebase origin/main\n</code></pre> <code>rebase</code> reapplies your commits on top of the new base, resulting in a cleaner, linear history.</p> Practice Problem 2: Validating After Conflict <p>You just resolved a conflict in a Kubernetes <code>Deployment.yaml</code>. What is the most important thing to do before committing the resolution?</p> Answer <p>Validate the syntax! Use a tool like <code>yq</code>, <code>yamllint</code>, or <code>kubectl diff</code>. A single indentation error during a manual merge resolution can prevent the file from being parsed by your CD pipeline.</p>"},{"location":"efficiency/git_workflows/#key-takeaways","title":"Key Takeaways","text":"Action Command / Strategy Syncing <code>git pull --rebase origin main</code> Branching <code>git checkout -b &lt;type&gt;/&lt;description&gt;</code> Updating <code>git rebase main</code> Cleaning <code>git commit --amend</code> (for fixups) Validating <code>yq eval '.' &lt;file&gt;</code>"},{"location":"efficiency/git_workflows/#further-reading","title":"Further Reading","text":""},{"location":"efficiency/git_workflows/#official-documentation","title":"Official Documentation","text":"<ul> <li>Git Branching - Workflows - From the Pro Git book.</li> <li>GitHub Flow - A simple, branch-based workflow.</li> </ul>"},{"location":"efficiency/git_workflows/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Trunk Based Development - An alternative to long-lived feature branches.</li> <li>GitLab Flow - Workflow incorporating environment branches (Staging, Production).</li> </ul>"},{"location":"efficiency/git_workflows/#deep-dives","title":"Deep Dives","text":"<ul> <li>DAG Manipulation - Understanding how <code>rebase</code> and <code>merge</code> rewrite the project graph.</li> <li>Infrastructure as Code Testing - Why linting and validation are critical parts of the Git workflow.</li> </ul>"},{"location":"efficiency/github_cli/","title":"GitHub CLI (gh): Workflow Automation","text":"<p>You've finished your code change. Now you have to open a browser, navigate to the repo, click \"New Pull Request,\" fill out the form, and add reviewers. There is a better way.</p> <p>The GitHub CLI (<code>gh</code>) brings the power of GitHub directly to your terminal. For SREs, this means you can manage PRs, view CI/CD status, and even interact with GitHub Actions without ever leaving your shell.</p>"},{"location":"efficiency/github_cli/#quick-start-get-productive-in-3-minutes","title":"Quick Start: Get Productive in 3 Minutes","text":"<ol> <li>Auth: <code>gh auth login</code></li> <li>Create a PR: <code>gh pr create --title \"feat: add vpc logging\" --body \"See Jira-123\"</code></li> <li>Check CI: <code>gh run watch</code> (Watch your GitHub Actions run in real-time)</li> <li>Merge: <code>gh pr merge --auto --squash</code></li> </ol>"},{"location":"efficiency/github_cli/#why-github-cli-matters-for-platform-work","title":"Why GitHub CLI Matters for Platform Work","text":"<p>SREs often manage dozens of repositories simultaneously. Using a browser for every PR or Action becomes a major friction point. <code>gh</code> allows you to treat GitHub as a command-line tool that can be integrated into your scripts and aliases.</p>"},{"location":"efficiency/github_cli/#common-scenarios","title":"Common Scenarios","text":"Tracking Deployments Mass PR Review Scripting GitHub <p>Instead of refreshing a browser tab, watch your deployment pipeline from your terminal: Watch Workflow<pre><code>gh run list --workflow deploy.yml --limit 5\ngh run watch # Follow the live logs of the latest run\n</code></pre></p> <p>Need to review three dependency updates from Dependabot? Review PRs<pre><code>gh pr list # See all open PRs\ngh pr checkout 123 # Quickly pull the code locally to test\ngh pr review --approve 123\n</code></pre></p> <p>Use <code>gh api</code> to perform complex tasks that aren't available in standard commands, returning clean JSON that you can pipe to <code>jq</code>. Find Large Repos<pre><code>gh api /orgs/my-org/repos | jq '.[] | select(.size &gt; 100000) | .name'\n</code></pre></p>"},{"location":"efficiency/github_cli/#essential-commands","title":"Essential Commands","text":"<ul> <li> <p> PR Management (<code>gh pr</code>)</p> <p>Why it matters: Create, list, view, and merge pull requests without a mouse.</p> <ul> <li><code>gh pr create</code></li> <li><code>gh pr status</code></li> <li><code>gh pr diff</code></li> </ul> </li> <li> <p> Actions Workflow (<code>gh run</code>)</p> <p>Why it matters: Monitor and trigger GitHub Actions. Invaluable for debugging failing CI/CD pipelines.</p> <ul> <li><code>gh run list</code></li> <li><code>gh run view --log</code></li> <li><code>gh workflow run deploy.yml</code></li> </ul> </li> <li> <p> API Access (<code>gh api</code>)</p> <p>Why it matters: Full access to the GitHub REST API. Perfect for building custom SRE tools.</p> </li> </ul>"},{"location":"efficiency/github_cli/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Speeding Up Merges <p>You've opened a PR and you know the CI will take 5 minutes. You don't want to wait around to click \"Merge.\" What command can you run to tell GitHub to merge the PR as soon as the checks pass?</p> Answer <p><pre><code>gh pr merge --auto --squash\n</code></pre> The <code>--auto</code> flag enables \"auto-merge,\" which will complete the merge automatically once all required status checks have passed.</p> Practice Problem 2: Debugging Actions <p>A GitHub Action failed, and you need to see the logs for the specific failed step. How do you do this without the UI?</p> Answer <p><pre><code>gh run view --log\n</code></pre> This will stream the logs of the most recent run directly to your terminal. You can even pipe this to <code>grep</code> or <code>jq</code> if the logs are structured!</p>"},{"location":"efficiency/github_cli/#key-takeaways","title":"Key Takeaways","text":"Command Purpose <code>gh pr create</code> Open a new Pull Request <code>gh run watch</code> Monitor Actions in real-time <code>gh pr checkout</code> Pull a PR's branch locally <code>gh repo clone</code> Intelligent cloning (handles SSH/HTTPS) <code>gh alias set</code> Create custom GitHub commands"},{"location":"efficiency/github_cli/#further-reading","title":"Further Reading","text":""},{"location":"efficiency/github_cli/#official-documentation","title":"Official Documentation","text":"<ul> <li>GitHub CLI Manual - Complete reference for every command.</li> <li>GitHub CLI Extension Guide - Learn how to build your own <code>gh</code> subcommands.</li> </ul>"},{"location":"efficiency/github_cli/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Lab (for GitLab) - A similar tool for GitLab users.</li> <li>Octokit - Official GitHub SDKs for building deeper integrations.</li> </ul>"},{"location":"efficiency/github_cli/#deep-dives","title":"Deep Dives","text":"<ul> <li>API Driven Development - How the GitHub CLI uses the same APIs you can access via <code>curl</code>.</li> <li>Workflow Automation - Principles of removing manual steps from the software lifecycle.</li> </ul>"},{"location":"efficiency/shell_productivity/","title":"Shell Productivity: FZF, Ripgrep, and Beyond","text":"<p>You've been typing <code>kubectl get pods -n production | grep api</code> for the hundredth time this week. You're scrolling through your shell history using the <code>Up</code> arrow, hoping to find that one <code>curl</code> command from Tuesday. There is a better way.</p> <p>Modern CLI tools can transform your terminal from a basic text interface into a high-performance development environment. These tools prioritize speed, fuzzy matching, and sensible defaults to help you find information in milliseconds.</p>"},{"location":"efficiency/shell_productivity/#the-big-three-multipliers","title":"The \"Big Three\" Multipliers","text":"<p>If you install nothing else, install these three tools to immediately accelerate your workflow.</p> <ul> <li> <p> fzf (Fuzzy Finder)</p> <p>Why it matters: Interactive fuzzy searching for files, history, and processes. It makes \"finding\" feel like \"browsing.\"</p> Fuzzy History Search<pre><code># Press Ctrl+r in your terminal\n# Type a few characters of a command you used yesterday\n</code></pre> <p>Key insight: <code>fzf</code> can be piped into anything. <code>cat $(fzf)</code> is a game changer.</p> </li> <li> <p> ripgrep (rg)</p> <p>Why it matters: The fastest search tool in existence. It respects <code>.gitignore</code> and skips binary/hidden files by default.</p> Search for Text<pre><code>rg \"api-key\" --type yaml\n</code></pre> <p>Key insight: It's often 10-100x faster than <code>grep</code>. Use it to find config keys across thousands of files.</p> </li> <li> <p> z (or zoxide)</p> <p>Why it matters: \"Smart\" directory jumping. It learns which directories you visit most often and lets you jump to them with a few keystrokes.</p> Jump to Directory<pre><code>z infrastructure  # Jumps to /home/user/projects/company/infrastructure\n</code></pre> <p>Key insight: Stop typing <code>cd ../../../path/to/thing</code>. Just <code>z thing</code>.</p> </li> </ul>"},{"location":"efficiency/shell_productivity/#why-shell-productivity-matters-for-platform-work","title":"Why Shell Productivity Matters for Platform Work","text":"<p>SREs spend a significant portion of their lives in the terminal. Saving 5 seconds on a command you run 50 times a day adds up to over 15 hours a year. More importantly, it reduces the cognitive load of \"managing the terminal,\" letting you focus on the actual problem.</p>"},{"location":"efficiency/shell_productivity/#common-scenarios","title":"Common Scenarios","text":"Searching History Finding the Right Config Better Listing (eza) <p>Instead of <code>history | grep command</code>, use <code>fzf</code>. - Press <code>Ctrl+r</code> - Start typing parts of the command in any order (e.g., <code>k8s api post</code>) - Use arrows to select and <code>Enter</code> to run.</p> <p>You know an environment variable is defined somewhere in your <code>docs/</code> or <code>k8s/</code> folder. - <code>rg \"MY_ENV_VAR\"</code> - Use <code>rg -l</code> to just see the filenames. - Pipe into <code>fzf</code> to select the file to edit: <code>vi $(rg -l \"pattern\" | fzf)</code></p> <p>Replace <code>ls</code> with <code>eza</code>. It provides colors, file type icons, and an integrated <code>git</code> status for every file. - <code>alias ls='eza --icons --git'</code></p>"},{"location":"efficiency/shell_productivity/#modern-tool-recap","title":"Modern Tool Recap","text":"Tool Replacement For Main Benefit <code>fzf</code> <code>grep</code> (for lists) Interactive, fuzzy selection <code>rg</code> <code>grep</code> Incredible speed, respects <code>.gitignore</code> <code>eza</code> <code>ls</code> Better visual info and Git integration <code>bat</code> <code>cat</code> Syntax highlighting and line numbers <code>fd</code> <code>find</code> Simpler syntax, faster defaults <code>zoxide</code> <code>cd</code> Memory-based jumping"},{"location":"efficiency/shell_productivity/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Combining Tools <p>How would you use <code>fzf</code> and <code>fd</code> together to find a file and open it in <code>vim</code> in a single command?</p> Answer <p><pre><code>vi $(fd --type f | fzf)\n</code></pre> <code>fd</code> generates the list of files, <code>fzf</code> lets you interactively pick one, and the <code>$()</code> subshell passes that filename to <code>vi</code>.</p> Practice Problem 2: Search and Edit <p>You need to find every YAML file that contains the string <code>deprecated-api</code> and open them all for editing.</p> Answer <p><pre><code>vi $(rg -l \"deprecated-api\" --type yaml)\n</code></pre> <code>rg -l</code> (lowercase L) outputs only the names of files containing matches.</p>"},{"location":"efficiency/shell_productivity/#further-reading","title":"Further Reading","text":""},{"location":"efficiency/shell_productivity/#official-documentation","title":"Official Documentation","text":"<ul> <li>fzf GitHub - Installation and advanced configuration.</li> <li>ripgrep User Guide - Deep dive into search patterns.</li> <li>Modern Unix - A curated list of modern replacements for classic Unix tools.</li> </ul>"},{"location":"efficiency/shell_productivity/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Starship - A fast, customizable shell prompt that shows Git and K8s context.</li> <li>Fish Shell - A shell with many of these features built-in.</li> </ul>"},{"location":"efficiency/shell_productivity/#deep-dives","title":"Deep Dives","text":"<ul> <li>Regex Mastery - Mastering the search patterns used by <code>rg</code> and <code>grep</code>.</li> <li>Fuzzy Matching Algorithms - How <code>fzf</code> calculates relevance from partial strings.</li> </ul>"},{"location":"efficiency/ssh_mastery/","title":"SSH Mastery: Beyond Simple Connections","text":"<p>You're juggling 50 different servers across three environments. You're tired of typing <code>ssh -i ~/.ssh/prod-key.pem ec2-user@10.0.4.122</code>. You need to access a private database that's only reachable from a jump host. This is why you need to master SSH.</p> <p>SSH (Secure Shell) is the primary interface for remote platform work. While basic usage is simple, mastering the SSH configuration and tunneling capabilities will save you hours of typing and enable complex remote workflows.</p>"},{"location":"efficiency/ssh_mastery/#the-secret-weapon-sshconfig","title":"The Secret Weapon: <code>~/.ssh/config</code>","text":"<p>Stop typing long commands. The SSH config file allows you to define aliases and settings for your frequently used hosts.</p> Example SSH Config<pre><code># Global settings\nHost *\n    ServerAliveInterval 60\n    AddKeysToAgent yes\n\n# A specific server\nHost prod-db\n    HostName 10.0.4.122\n    User ec2-user\n    IdentityFile ~/.ssh/prod-key.pem\n\n# Connecting through a Bastion\nHost internal-svc\n    HostName 192.168.1.50\n    ProxyJump bastion-host  # (1)!\n</code></pre> <ol> <li>Automatically tunnels your connection through another host.</li> </ol>"},{"location":"efficiency/ssh_mastery/#quick-start-ssh-key-management","title":"Quick Start: SSH Key Management","text":"<ol> <li>Generate a modern key: <code>ssh-keygen -t ed25519 -C \"your_email@example.com\"</code></li> <li>Use the Agent: <code>ssh-add ~/.ssh/id_ed25519</code> (Stops you from typing your passphrase every time).</li> <li>Copy to Server: <code>ssh-copy-id user@host</code> (No more password prompts).</li> </ol>"},{"location":"efficiency/ssh_mastery/#why-ssh-mastery-matters-for-platform-work","title":"Why SSH Mastery Matters for Platform Work","text":"<p>SREs are \"network navigators.\" You often need to bridge the gap between your local environment and a restricted remote VPC.</p>"},{"location":"efficiency/ssh_mastery/#common-scenarios","title":"Common Scenarios","text":"Local Port Forwarding Agent Forwarding Persistent Connections (ControlMaster) <p>Access a remote service (like a database or web UI) as if it were running on your own laptop. Tunnel to Remote DB<pre><code>ssh -L 5432:localhost:5432 prod-db\n</code></pre> Now, point your local DB client to <code>localhost:5432</code>. SSH tunnels the traffic securely to the remote database.</p> <p>You need to use your local Git keys on a remote server to clone a repo. - Don't copy your private keys to the server. - Do use <code>ssh -A user@host</code>. - Your local SSH agent \"lends\" its keys to the remote session temporarily.</p> <p>Tired of the 2-second delay every time you run a command over SSH? Speed up SSH<pre><code>Host *\n    ControlMaster auto\n    ControlPath ~/.ssh/sockets/%r@%h:%p\n    ControlPersist 10m\n</code></pre> The first connection stays open in the background. Subsequent connections happen instantly.</p>"},{"location":"efficiency/ssh_mastery/#essential-ssh-shortcuts","title":"Essential SSH Shortcuts","text":"<ul> <li> <p> The Escape Sequence (<code>~.</code>)</p> <p>Why it matters: If a remote server freezes, you can't type <code>exit</code>. Press <code>Enter</code>, then <code>~</code>, then <code>.</code> to kill the connection immediately.</p> </li> <li> <p> SCP and SFTP</p> <p>Why it matters: Fast file transfers using the same credentials as your SSH session.</p> Copy File<pre><code>scp local-script.sh user@host:/tmp/\n</code></pre> </li> <li> <p> Remote Port Forwarding (<code>-R</code>)</p> <p>Why it matters: Let someone else access a service running on your laptop. Use with caution!</p> </li> </ul>"},{"location":"efficiency/ssh_mastery/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: ProxyJump vs. SSH Tunnels <p>You need to reach a server in a private subnet. You can SSH into a Bastion host in the public subnet. What is the modern, cleanest way to configure this in your <code>~/.ssh/config</code>?</p> Answer <p>Use <code>ProxyJump</code>.  <pre><code>Host private-server\n    HostName 10.0.1.5\n    ProxyJump bastion-host\n</code></pre> This is much simpler and safer than manual <code>-L</code> or <code>-W</code> tunneling.</p> Practice Problem 2: Security <p>Is it safe to use SSH Agent Forwarding (<code>-A</code>) when connecting to a server you don't fully trust?</p> Answer <p>No. While your private key is never copied to the server, anyone with root access on that remote server can \"talk\" to your local agent and use your identities as long as you are connected. Only use <code>-A</code> on trusted infrastructure.</p>"},{"location":"efficiency/ssh_mastery/#key-takeaways","title":"Key Takeaways","text":"Feature Flag / Setting Purpose Local Tunnel <code>-L</code> Access remote service locally Jump Host <code>-J</code> or <code>ProxyJump</code> Connect through a bastion Agent Forwarding <code>-A</code> Use local keys on remote host Config File <code>~/.ssh/config</code> Alias and simplify connections Kill Session <code>Enter ~ .</code> Emergency disconnect"},{"location":"efficiency/ssh_mastery/#further-reading","title":"Further Reading","text":""},{"location":"efficiency/ssh_mastery/#official-documentation","title":"Official Documentation","text":"<ul> <li>OpenSSH Official Site - The home of the project.</li> <li><code>man ssh_config</code> - Detailed documentation of every possible config option.</li> </ul>"},{"location":"efficiency/ssh_mastery/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Mosh - Better than SSH for roaming and intermittent connections.</li> <li>Ansible - Uses SSH for automated configuration management.</li> </ul>"},{"location":"efficiency/ssh_mastery/#deep-dives","title":"Deep Dives","text":"<ul> <li>Public Key Infrastructure - The theory behind how SSH keys keep you secure.</li> <li>Network Layer Abstractions - Understanding how port forwarding works at the transport layer.</li> </ul>"},{"location":"efficiency/tmux/","title":"Terminal Multiplexing with tmux","text":"<p>Your SSH connection just dropped during a long-running database migration. Without a multiplexer, your session is gone, and the process might be in an unknown state. With <code>tmux</code>, you just reconnect and pick up exactly where you left off. This is why <code>tmux</code> is a non-negotiable tool for SREs.</p> <p><code>tmux</code> (Terminal Multiplexer) lets you manage multiple terminal sessions from a single window. More importantly, it keeps those sessions alive on the server even if your connection breaks.</p>"},{"location":"efficiency/tmux/#quick-start-the-3-command-survival-guide","title":"Quick Start: The 3-Command Survival Guide","text":"<p>If you're new to <code>tmux</code>, these three commands provide 90% of the value:</p> <ol> <li>Start a session: <code>tmux new -s my-work</code></li> <li>Detach (Leave it running): Press <code>Ctrl+b</code> then <code>d</code></li> <li>Attach (Get back to it): <code>tmux attach -t my-work</code></li> </ol>"},{"location":"efficiency/tmux/#how-tmux-works","title":"How Tmux Works","text":"<p><code>tmux</code> sits between your terminal emulator and the shell. It manages a Server that hosts multiple Sessions. Each session can have multiple Windows, and each window can be split into multiple Panes.</p> <pre><code>graph TD\n    Server[Tmux Server] --&gt; SessionA[Session: Incident-123]\n    Server --&gt; SessionB[Session: Maintenance]\n\n    SessionA --&gt; Win1[Window 1: Logs]\n    SessionA --&gt; Win2[Window 2: Editor]\n\n    Win1 --&gt; Pane1[Pane: tail -f access.log]\n    Win1 --&gt; Pane2[Pane: htop]</code></pre>"},{"location":"efficiency/tmux/#the-prefix-key","title":"The Prefix Key","text":"<p>Most <code>tmux</code> commands are triggered by a Prefix. By default, this is <code>Ctrl+b</code>. You press the prefix, release it, and then press the command key.</p> <ul> <li> <p> Window Management</p> <p>Why it matters: Keep different tasks (logging, editing, monitoring) in separate \"tabs\" within one SSH session.</p> <ul> <li><code>Prefix</code> + <code>c</code>: Create a new window</li> <li><code>Prefix</code> + <code>n</code> / <code>p</code>: Next/Previous window</li> <li><code>Prefix</code> + <code>0-9</code>: Jump to specific window</li> </ul> </li> <li> <p>:material-columns: Pane Management</p> <p>Why it matters: Watch logs and run commands side-by-side in the same view.</p> <ul> <li><code>Prefix</code> + <code>\"</code>: Split horizontally</li> <li><code>Prefix</code> + <code>%</code>: Split vertically</li> <li><code>Prefix</code> + <code>Arrow Keys</code>: Move between panes</li> <li><code>Prefix</code> + <code>z</code>: Zoom (maximize) the current pane</li> </ul> </li> <li> <p> Session Management</p> <p>Why it matters: Persist your work across reboots or connection drops.</p> <ul> <li><code>tmux ls</code>: List running sessions</li> <li><code>tmux attach</code>: Reconnect to the last session</li> <li><code>Prefix</code> + <code>d</code>: Detach (disconnect without killing)</li> </ul> </li> </ul>"},{"location":"efficiency/tmux/#why-tmux-matters-for-platform-work","title":"Why Tmux Matters for Platform Work","text":"<p>For an SRE, <code>tmux</code> is about resilience and multitasking.</p>"},{"location":"efficiency/tmux/#common-scenarios","title":"Common Scenarios","text":"Connection Resilience Incident War Room Shared Troubleshooting <p>When performing risky operations (like upgrading a kernel or migrating a database), always run them inside a <code>tmux</code> session. If your VPN drops or your Wi-Fi flutters, the operation continues safely on the server.</p> <p>Split your screen into four quadrants: - Top Left: <code>tail -f</code> the error logs - Top Right: <code>htop</code> for system resources - Bottom Left: <code>kubectl get pods -w</code> - Bottom Right: A shell for active troubleshooting</p> <p>Two people can attach to the same <code>tmux</code> session on a server. This is a \"poor man's screen sharing\" that is incredibly effective for remote pair-debugging without any special software.</p>"},{"location":"efficiency/tmux/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: The Panic Button <p>You're inside <code>tmux</code> and everything is frozen. How do you kill the entire session and get back to your normal shell?</p> Answer <p>Type <code>exit</code> in every pane, or use the command <code>Prefix</code> + <code>:kill-session</code> followed by <code>Enter</code>. If you're completely stuck, you can run <code>tmux kill-server</code> from outside <code>tmux</code> in another terminal.</p> Practice Problem 2: Finding Your Way <p>You have 10 windows open in a session and forgot which one has your editor. What's the fastest way to see a list of all windows and pick one?</p> Answer <p>Press <code>Prefix</code> + <code>w</code>. This opens an interactive, searchable list of all windows and panes. You can use the arrow keys to navigate and <code>Enter</code> to switch to the selected one.</p>"},{"location":"efficiency/tmux/#key-takeaways","title":"Key Takeaways","text":"Action Command / Shortcut Prefix <code>Ctrl+b</code> (Default) New Session <code>tmux new -s &lt;name&gt;</code> Detach <code>Prefix</code> + <code>d</code> Attach <code>tmux attach -t &lt;name&gt;</code> Split Vertically <code>Prefix</code> + <code>%</code> Split Horizontally <code>Prefix</code> + <code>\"</code> Zoom Pane <code>Prefix</code> + <code>z</code>"},{"location":"efficiency/tmux/#further-reading","title":"Further Reading","text":""},{"location":"efficiency/tmux/#official-documentation","title":"Official Documentation","text":"<ul> <li>Tmux Wiki - The official source for documentation and FAQs.</li> <li><code>man tmux</code> - The comprehensive manual page.</li> </ul>"},{"location":"efficiency/tmux/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>tmate - Instant terminal sharing based on tmux.</li> <li>tmux-resurrect - Plugin to persist sessions across system reboots.</li> </ul>"},{"location":"efficiency/tmux/#deep-dives","title":"Deep Dives","text":"<ul> <li>The Tao of Tmux - A philosophical and technical deep dive into tmux workflows.</li> <li>Persistent SSH Connections - Understanding the abstraction of persistent sessions in distributed systems.</li> </ul>"},{"location":"efficiency/vscode_remote/","title":"VS Code Remote: Editing on Servers Without Pain","text":"<p>You're editing a complex Terraform module or a Python script on a remote server. You could use <code>vim</code> or <code>nano</code> via SSH, but you miss your extensions, your debugger, and your familiar keybindings. This is why VS Code Remote exists.</p> <p>The VS Code Remote - SSH extension lets you use a local VS Code installation to open a folder on a remote machine. It feels exactly like working locally, but the files, the terminal, and the extensions run on the remote server.</p>"},{"location":"efficiency/vscode_remote/#quick-start-get-productive-in-2-minutes","title":"Quick Start: Get Productive in 2 Minutes","text":"<ol> <li>Install the Extension: Search for \"Remote - SSH\" in the VS Code Extensions view.</li> <li>Connect: Click the green \"Remote Window\" button in the bottom-left corner of VS Code.</li> <li>Enter Details: Select \"Connect to Host...\" and type <code>user@hostname</code>.</li> <li>Open Folder: Once connected, go to \"File &gt; Open Folder\" and browse the remote filesystem.</li> </ol>"},{"location":"efficiency/vscode_remote/#how-it-works-the-client-server-model","title":"How It Works: The Client-Server Model","text":"<p>VS Code splits its architecture. The Client (the UI you see) runs on your laptop. The Server (the logic, language services, and terminal) is automatically installed and run on the remote machine.</p> <pre><code>graph LR\n    subgraph \"Local Laptop\"\n        UI[VS Code UI]\n        Theme[Themes &amp; Keybindings]\n    end\n\n    subgraph \"Remote Server\"\n        Srv[VS Code Remote Server]\n        Ext[Language Extensions]\n        FS[Filesystem]\n        Term[Remote Terminal]\n    end\n\n    UI &lt;--&gt;|SSH Tunnel| Srv\n    Srv &lt;--&gt; FS\n    Srv &lt;--&gt; Term\n    Srv &lt;--&gt; Ext</code></pre>"},{"location":"efficiency/vscode_remote/#why-it-matters-for-platform-work","title":"Why It Matters for Platform Work","text":"<p>SREs often work in environments where data or services are only accessible from within a specific VPC or through a bastion host. VS Code Remote allows you to bring a world-class IDE into those restricted environments.</p>"},{"location":"efficiency/vscode_remote/#common-scenarios","title":"Common Scenarios","text":"Bastion/Jump Hosts:material-python: Remote Debugging Inside Containers <p>You can configure VS Code to automatically \"jump\" through a bastion host to reach a private server. - Setup your <code>~/.ssh/config</code> with <code>ProxyJump</code>. - VS Code will respect this configuration and connect seamlessly.</p> <p>Debugging a Python script that fails only on a specific server? - Connect via VS Code Remote. - Set breakpoints in the editor. - Hit <code>F5</code>. The debugger runs on the server, but you control it from your laptop.</p> <p>The same technology allows you to \"Remote into\" a running Docker container. This is invaluable for inspecting the environment of a failing service or exploring a complex container image.</p>"},{"location":"efficiency/vscode_remote/#essential-remote-extensions","title":"Essential Remote Extensions","text":"<p>When working remotely, these extensions run on the server and provide massive value:</p> <ul> <li> <p>:material-yaml: YAML / Kubernetes</p> <p>Why it matters: Real-time validation and linting of K8s manifests directly on the server where they'll be applied.</p> </li> <li> <p> HashiCorp Terraform</p> <p>Why it matters: Autocomplete for providers and modules, ensuring your IaC changes are syntactically correct before you run <code>plan</code>.</p> </li> <li> <p> Python (Pylance)</p> <p>Why it matters: Full IntelliSense and type checking for your automation scripts, even when they rely on remote-only libraries.</p> </li> </ul>"},{"location":"efficiency/vscode_remote/#key-takeaways","title":"Key Takeaways","text":"Feature Benefit SSH Tunneling Secure connection to any server you can SSH into Local Feel Use your favorite themes, fonts, and shortcuts Remote Terminal Integrated terminal runs directly on the server Port Forwarding Access remote web services (like <code>localhost:8080</code>) on your local browser"},{"location":"efficiency/vscode_remote/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Port Forwarding <p>You're running a web server on a remote machine on port <code>8000</code>. It's not accessible via the public internet. How can VS Code help you see the webpage in your local browser?</p> Answer <p>Use Port Forwarding. In the \"Ports\" tab of the integrated terminal, click \"Forward a Port\" and enter <code>8000</code>. VS Code will create a secure tunnel, and you can now visit <code>http://localhost:8000</code> on your laptop to see the remote content.</p> Practice Problem 2: Extension Installation <p>You installed a \"Theme\" extension and a \"Python\" extension while connected to a remote server. Where do these extensions actually live?</p> Answer <p>The Theme extension lives on your local laptop (UI extensions). The Python extension (language service) lives on the remote server (Workspace extensions). VS Code manages this split automatically.</p>"},{"location":"efficiency/vscode_remote/#further-reading","title":"Further Reading","text":""},{"location":"efficiency/vscode_remote/#official-documentation","title":"Official Documentation","text":"<ul> <li>VS Code Remote - SSH Documentation - Official guide and troubleshooting.</li> <li>SSH Config File Reference - How to optimize your SSH setup for VS Code.</li> </ul>"},{"location":"efficiency/vscode_remote/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Tramp (Emacs) - The original remote editing solution.</li> <li>Mosh - A mobile shell that handles intermittent connectivity better than SSH.</li> </ul>"},{"location":"efficiency/vscode_remote/#deep-dives","title":"Deep Dives","text":"<ul> <li>Client-Server Architecture - Understanding the separation of concerns in modern development tools.</li> <li>Network Tunneling - How SSH tunnels facilitate remote development.</li> </ul>"},{"location":"essentials/jq_parsing_json/","title":"JQ: Parsing API Responses and Logs","text":"<p>It's 2am. The API is returning errors. You SSH into the server, <code>curl</code> the endpoint, and get back 500 lines of JSON. You squint at the terminal trying to find the error message buried somewhere in that wall of text. This is why <code>jq</code> exists.</p> <p><code>jq</code> is a lightweight and flexible command-line JSON processor. It's like <code>sed</code>, <code>awk</code>, and <code>grep</code> specifically designed for JSON data. For SREs and Platform Engineers, <code>jq</code> is an essential tool for parsing API responses, filtering logs, and transforming data during incident response and automation.</p>"},{"location":"essentials/jq_parsing_json/#installation","title":"Installation","text":"<p>Before you can use <code>jq</code>, you need to install it:</p>  Linux macOS Windows Install JQ on Linux<pre><code># Debian/Ubuntu\nsudo apt-get update &amp;&amp; sudo apt-get install jq\n\n# RHEL/CentOS/Fedora\nsudo dnf install jq\n\n# Arch Linux\nsudo pacman -S jq\n</code></pre> Install JQ on macOS<pre><code># Using Homebrew\nbrew install jq\n\n# Using MacPorts\nsudo port install jq\n</code></pre> Install JQ on Windows<pre><code># Using Chocolatey\nchoco install jq\n\n# Using Scoop\nscoop install jq\n\n# Or download binary from https://jqlang.github.io/jq/download/\n</code></pre> <p>Verify installation:</p> Check JQ Version<pre><code>jq --version\n# Output: jq-1.7.1 (or similar)\n</code></pre>"},{"location":"essentials/jq_parsing_json/#quick-start-get-productive-in-5-minutes","title":"Quick Start: Get Productive in 5 Minutes","text":"<p>You can start using <code>jq</code> immediately with these essential patterns.</p> Common JQ Operations<pre><code># Pretty-print JSON\ncurl -s https://api.github.com/repos/stedolan/jq | jq '.'\n\n# Extract a specific field\ncurl -s https://api.github.com/repos/stedolan/jq | jq '.description'\n\n# Extract multiple fields into a new object\ncurl -s https://api.github.com/repos/stedolan/jq | jq '{name: .name, stars: .stargazers_count}'\n\n# Filter an array\ncat pods.json | jq '.items[] | select(.status.phase == \"Running\") | .metadata.name'\n</code></pre>"},{"location":"essentials/jq_parsing_json/#how-jq-works","title":"How JQ Works","text":"<p><code>jq</code> operates on a stream of JSON entities. It takes an input, applies a filter, and sends the result to standard output.</p> <pre><code>graph TD\n    Input[JSON Input&lt;br/&gt;from API/file/pipe]\n    Filter[JQ Filter&lt;br/&gt;e.g., .items[]]\n    Output[Transformed&lt;br/&gt;JSON/Text]\n\n    Input --&gt; Filter\n    Filter --&gt; Output\n\n    style Input fill:#2d3748,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style Filter fill:#2f855a,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style Output fill:#2d3748,stroke:#cbd5e0,stroke-width:2px,color:#fff</code></pre> <ul> <li> <p> The Identity Filter (<code>.</code>)</p> <p>Why it matters: The simplest filter. It takes the input and outputs it exactly as is, but pretty-printed by default.</p> Pretty Print<pre><code>echo '{\"foo\": \"bar\"}' | jq '.'\n</code></pre> <p>Key insight: Use this as your \"first pass\" to understand the structure of unknown JSON.</p> </li> <li> <p> Object Identifier (<code>.foo</code>)</p> <p>Why it matters: Extracts the value associated with a key.</p> Extract Field<pre><code>echo '{\"status\": \"ok\"}' | jq '.status'\n</code></pre> <p>Key insight: You can chain these for nested data: <code>.metadata.name</code>.</p> </li> <li> <p> Array Iterator (<code>.[]</code>)</p> <p>Why it matters: \"Unpacks\" an array, outputting each element individually.</p> Iterate Array<pre><code>echo '[1, 2, 3]' | jq '.[]'\n</code></pre> <p>Key insight: Essential for processing lists of pods, nodes, or log entries.</p> </li> </ul>"},{"location":"essentials/jq_parsing_json/#why-jq-matters-for-platform-work","title":"Why JQ Matters for Platform Work","text":"<p>In a world where everything is an API, JSON is the universal language. Whether you're debugging Kubernetes manifests, parsing CloudTrail logs, or interacting with a proprietary internal service, <code>jq</code> lets you cut through the noise.</p>"},{"location":"essentials/jq_parsing_json/#common-scenarios","title":"Common Scenarios","text":"Kubernetes Debugging Cloud API Parsing Log Analysis <p>Extract all pod names and their statuses from a namespace:</p> List Pod Statuses<pre><code>kubectl get pods -o json | jq '.items[] | {name: .metadata.name, status: .status.phase}'\n</code></pre> <p>Find the Instance ID of all running EC2 instances with a specific tag:</p> Filter AWS Instances<pre><code>aws ec2 describe-instances --output json | jq '.Reservations[].Instances[] | select(.State.Name==\"running\") | .InstanceId'\n</code></pre> <p>Parse structured JSON logs to find high-latency requests:</p> Find Slow Requests<pre><code>cat access.log | jq 'select(.latency_ms &gt; 500) | {timestamp, path, latency: .latency_ms}'\n</code></pre>"},{"location":"essentials/jq_parsing_json/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Extracting from Arrays <p>Given the JSON <code>{\"users\": [{\"id\": 1, \"name\": \"Alice\"}, {\"id\": 2, \"name\": \"Bob\"}]}</code>, how would you extract just the names of all users?</p> Answer <p><pre><code>echo '{\"users\": [{\"id\": 1, \"name\": \"Alice\"}, {\"id\": 2, \"name\": \"Bob\"}]}' | jq '.users[].name'\n</code></pre> The <code>.users</code> part gets the array, <code>[]</code> iterates over its elements, and <code>.name</code> extracts the field from each element.</p> Practice Problem 2: Filtering <p>How would you filter a list of numbers <code>[10, 25, 5, 40]</code> to only show those greater than 20?</p> Answer <p><pre><code>echo '[10, 25, 5, 40]' | jq '.[] | select(. &gt; 20)'\n</code></pre> <code>select()</code> is a powerful built-in function that keeps only the elements for which the expression inside is true.</p>"},{"location":"essentials/jq_parsing_json/#key-takeaways","title":"Key Takeaways","text":"Filter Description <code>.</code> The identity filter (pretty-prints input) <code>.foo</code> Extract field \"foo\" from an object <code>.[]</code> Iterate over elements in an array <code>select(condition)</code> Keep only elements matching the condition <code>|</code> Pipe the output of one filter into the next"},{"location":"essentials/jq_parsing_json/#common-pitfalls","title":"Common Pitfalls","text":"<p>Even experienced users hit these <code>jq</code> gotchas:</p> <ul> <li> <p> Forgetting to Quote the Filter</p> Wrong - Shell Interprets Braces<pre><code>jq .items[] data.json  # \u274c Shell sees [] as glob pattern\n</code></pre> Correct - Always Quote<pre><code>jq '.items[]' data.json  # \u2705 Filter passed to jq correctly\n</code></pre> </li> <li> <p> Pipe Confusion</p> <p><code>jq</code> uses <code>|</code> for its own pipeline. Don't confuse it with shell pipes:</p> JQ Pipe (Inside Filter)<pre><code>jq '.items[] | select(.status == \"active\")' data.json\n</code></pre> Shell Pipe (Between Commands)<pre><code>curl api.example.com | jq '.items[]'\n</code></pre> </li> <li> <p> Array vs Array Elements</p> <p><code>.items</code> returns the whole array. <code>.items[]</code> iterates elements:</p> Understand the Difference<pre><code>echo '{\"items\":[1,2,3]}' | jq '.items'    # [1,2,3]\necho '{\"items\":[1,2,3]}' | jq '.items[]'  # 1\\n2\\n3\n</code></pre> </li> </ul>"},{"location":"essentials/jq_parsing_json/#whats-next","title":"What's Next","text":"<p>Now that you've mastered JSON parsing with <code>jq</code>, explore these related tools:</p> <ul> <li>YQ - Apply the same filtering approach to YAML files (K8s manifests, Ansible playbooks)</li> <li>Git for Infrastructure - Version control for configs and scripts that use <code>jq</code></li> <li>Shell Productivity - Combine <code>jq</code> with <code>fzf</code> and aliases to save even more time</li> </ul>"},{"location":"essentials/jq_parsing_json/#further-reading","title":"Further Reading","text":""},{"location":"essentials/jq_parsing_json/#official-documentation","title":"Official Documentation","text":"<ul> <li>JQ Manual - The definitive reference for all filters and functions</li> <li>JQ Playground - Interactive online tool to test your <code>jq</code> filters</li> <li>JQ Download - Installation packages for all platforms</li> </ul>"},{"location":"essentials/jq_parsing_json/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>yq - Like <code>jq</code> but for YAML</li> <li>fx - Terminal JSON viewer and processor with interactive UI</li> <li>jless - Modern JSON viewer with vim-style navigation</li> </ul>"},{"location":"essentials/jq_parsing_json/#deep-dives","title":"Deep Dives","text":"<ul> <li>JQ Cookbook - Common patterns and recipes for complex transformations</li> <li>Parsing JSON in Shell - Understand the underlying theory of how <code>jq</code> parses data</li> </ul> <p>Part of Essentials: This article is part of the \ud83d\udce6 Essentials series - core tools you need today for platform work.</p>"},{"location":"essentials/regex_for_sres/","title":"Regular Expressions for SREs","text":"<p>You're searching through 10GB of logs for an IP address. You need to find all lines that contain \"ERROR\" but NOT \"404\". You're trying to rename 500 files that follow a specific naming pattern. This is why you need Regex.</p> <p>Regular Expressions (Regex) are a powerful language for pattern matching in text. For an SRE, Regex is the \"Swiss Army Knife\" of data processing. Whether you're using <code>grep</code>, <code>sed</code>, <code>awk</code>, or writing a Python script, Regex allows you to find and transform data with surgical precision.</p>"},{"location":"essentials/regex_for_sres/#quick-start-the-survival-syntax","title":"Quick Start: The \"Survival\" Syntax","text":"<p>If you know these characters, you can solve 80% of your log-searching problems.</p> Character Meaning Example <code>.</code> Any single character <code>a.c</code> matches <code>abc</code>, <code>a1c</code> <code>*</code> Zero or more of previous <code>ab*</code> matches <code>a</code>, <code>ab</code>, <code>abbb</code> <code>^</code> Start of the line <code>^Error</code> matches lines starting with \"Error\" <code>$</code> End of the line <code>done$</code> matches lines ending with \"done\" <code>[ ]</code> Any character in brackets <code>[0-9]</code> matches any digit `` Escape (treat next literally) <code>\\.</code> matches a literal dot"},{"location":"essentials/regex_for_sres/#why-regex-matters-for-platform-work","title":"Why Regex Matters for Platform Work","text":"<p>SREs spend much of their time searching for needles in haystacks. Logs, configurations, and API responses are all text. Regex is the filter that removes the noise.</p>"},{"location":"essentials/regex_for_sres/#common-scenarios","title":"Common Scenarios","text":"Finding IP Addresses Cleaning Data with sed Complex Filtering <p>Searching for an IP in a log file: Find IPs<pre><code>grep -E \"[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\" access.log\n</code></pre> (Note: This is a \"simple\" version; a perfect IP regex is much longer!)</p> <p>Transforming a list of <code>host:port</code> into just <code>host</code>: Extract Host<pre><code>echo \"prod-db:5432\" | sed 's/:.*//'\n</code></pre> The <code>s/pattern/replacement/</code> command in <code>sed</code> is the gold standard for text transformation.</p> <p>Find lines that have an error code between 500 and 599: Find Server Errors<pre><code>grep \"HTTP/1.1 5[0-9][0-9]\" access.log\n</code></pre></p>"},{"location":"essentials/regex_for_sres/#the-power-of-capture-groups","title":"The Power of Capture Groups","text":"<p>Capture groups <code>( )</code> allow you to extract specific parts of a match and reuse them.</p> <p>Reformatting Dates<pre><code># Change DD-MM-YYYY to YYYY-MM-DD\necho \"31-12-2023\" | sed -E 's/([0-9]{2})-([0-9]{2})-([0-9]{4})/\\3-\\2-\\1/'\n</code></pre> The <code>\\1</code>, <code>\\2</code>, and <code>\\3</code> refer to the text matched inside the first, second, and third sets of parentheses.</p>"},{"location":"essentials/regex_for_sres/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Anchors <p>How do you search for the word <code>STOP</code> only when it appears at the very beginning of a line?</p> Answer <p><pre><code>grep \"^STOP\" file.txt\n</code></pre> The <code>^</code> anchor ensures the match only happens if \"STOP\" is the first thing on the line.</p> Practice Problem 2: Wildcards <p>What does the regex <code>.*</code> match?</p> Answer <p>It matches everything (or nothing). <code>.</code> matches any character, and <code>*</code> means \"zero or more of the previous.\" Together, they match the entire rest of a line.</p>"},{"location":"essentials/regex_for_sres/#key-takeaways","title":"Key Takeaways","text":"Pattern Match <code>\\d</code> Any digit (shorthand for <code>[0-9]</code>) <code>\\w</code> Any word character (alphanumeric + underscore) <code>+</code> One or more of the previous <code>?</code> Zero or one of the previous (optional) <code>\\|</code> OR (e.g., <code>ERROR\\|CRITICAL</code>)"},{"location":"essentials/regex_for_sres/#further-reading","title":"Further Reading","text":""},{"location":"essentials/regex_for_sres/#official-documentation","title":"Official Documentation","text":"<ul> <li>Regex101 - The best interactive tool for testing and explaining your regex.</li> <li>GNU Grep Manual - For the definitive word on how <code>grep</code> handles patterns.</li> </ul>"},{"location":"essentials/regex_for_sres/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>ripgrep (rg) - The fastest way to use regex on your filesystem.</li> <li>Perl-Compatible Regular Expressions (PCRE) - The \"advanced\" flavor of regex used by many modern tools.</li> </ul>"},{"location":"essentials/regex_for_sres/#deep-dives","title":"Deep Dives","text":"<ul> <li>Regular Expressions Theory - Deep dive into how regex engines work (Finite State Machines).</li> <li>Text Processing Philosophy - Why treating everything as text is the Unix philosophy.</li> </ul>"},{"location":"essentials/terminal_diagnostics/","title":"Terminal Diagnostics: The SRE's Vital Signs","text":"<p>The system is slow. Users are reporting timeouts. You SSH into the server and the prompt feels sluggish. What do you look for first?</p> <p>Terminal diagnostic tools are the \"stethoscopes\" of the platform engineer. They allow you to observe the health of the CPU, memory, disk, and network in real-time. Mastering these tools is the difference between guessing what's wrong and knowing exactly where the bottleneck lies.</p>"},{"location":"essentials/terminal_diagnostics/#quick-start-the-first-60-seconds-checklist","title":"Quick Start: The \"First 60 Seconds\" Checklist","text":"<p>When you land on a server during an incident, run these in order:</p> <ol> <li>Check load and CPU: <code>htop</code> (or <code>top</code>)</li> <li>Check memory: <code>free -h</code></li> <li>Check disk space: <code>df -h</code></li> <li>Check disk I/O: <code>iostat -xz 1</code> (requires <code>sysstat</code>)</li> <li>Check network connections: <code>ss -tulpn</code></li> <li>Check kernel logs: <code>dmesg -T | tail -n 50</code></li> </ol>"},{"location":"essentials/terminal_diagnostics/#essential-diagnostic-tools","title":"Essential Diagnostic Tools","text":"<ul> <li> <p> htop / top</p> <p>Why it matters: Real-time view of process activity. <code>htop</code> is preferred for its color-coded bars and ability to scroll/kill processes interactively.</p> <p>Key insight: Look for the \"Load Average.\" If it's significantly higher than the number of CPU cores, your system is oversaturated.</p> </li> <li> <p> free -h</p> <p>Why it matters: Shows total, used, and available memory in human-readable format.</p> <p>Key insight: Don't panic if \"free\" is low but \"available\" is high. Linux uses unused RAM for caching (buff/cache).</p> </li> <li> <p> df -h and du -sh</p> <p>Why it matters: <code>df</code> shows partition usage; <code>du</code> finds which specific directory is eating your space.</p> <p>Key insight: A 100% full disk often causes silent failures in databases and logging agents.</p> </li> </ul>"},{"location":"essentials/terminal_diagnostics/#why-diagnostics-matter-for-platform-work","title":"Why Diagnostics Matter for Platform Work","text":"<p>Diagnostics are the foundation of Incident Response. You cannot fix what you cannot measure. In a distributed system, being able to quickly rule out \"the server is full\" or \"the process is OOMing\" saves precious time.</p>"},{"location":"essentials/terminal_diagnostics/#common-scenarios","title":"Common Scenarios","text":"High CPU Usage Port Conflicts Ghost Files <p>Identify the process hogging the CPU: - Run <code>htop</code>. - Press <code>P</code> to sort by CPU usage. - If it's a Java or Python app, it might be an infinite loop or heavy GC. - Use <code>strace -p &lt;pid&gt;</code> to see what system calls the process is making in real-time.</p> <p>Why won't your new Nginx container start? - <code>ss -tulpn | grep :80</code> - This shows you exactly which process ID (PID) is already listening on port 80. - <code>ss</code> is the modern replacement for the older <code>netstat</code>.</p> <p><code>df</code> says the disk is full, but <code>du</code> can't find the files? - A process might be holding a deleted file open. - Use <code>lsof +L1</code> to find deleted files that are still consuming space because a process hasn't closed them.</p>"},{"location":"essentials/terminal_diagnostics/#key-diagnostic-commands","title":"Key Diagnostic Commands","text":"Command Purpose Modern Alternative <code>top</code> CPU/Process monitor <code>htop</code>, <code>btop</code> <code>netstat</code> Network connections <code>ss</code> <code>ifconfig</code> Interface config <code>ip addr</code> <code>find</code> Finding files <code>fd</code> <code>du</code> Disk usage per dir <code>dust</code> <code>tail -f</code> Follow logs <code>multitail</code>"},{"location":"essentials/terminal_diagnostics/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Identifying Memory Pressure <p>You run <code>free -h</code> and see that <code>free</code> is 100MB, but <code>available</code> is 4GB. Should you be worried about an Out-of-Memory (OOM) event?</p> Answer <p>No. Linux is designed to use almost all available RAM for disk caching to improve performance. The <code>available</code> column is the one that matters\u2014it tells you how much memory can be reclaimed for new processes without causing the system to swap.</p> Practice Problem 2: Finding a Process <p>You need to find the PID of a running process named <code>sidekiq</code> so you can kill it. What's the fastest command?</p> Answer <p><pre><code>pgrep -af sidekiq\n</code></pre> <code>pgrep</code> finds the PID, and <code>-af</code> shows the full command line so you can be sure you're targeting the right instance.</p>"},{"location":"essentials/terminal_diagnostics/#further-reading","title":"Further Reading","text":""},{"location":"essentials/terminal_diagnostics/#official-documentation","title":"Official Documentation","text":"<ul> <li>The Brendan Gregg Blog - The gold standard for Linux performance analysis.</li> <li><code>man proc</code> - Understand the <code>/proc</code> filesystem where all this data comes from.</li> </ul>"},{"location":"essentials/terminal_diagnostics/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>btop - A high-performance, beautiful system monitor.</li> <li>Glances - An all-in-one cross-platform monitoring tool.</li> </ul>"},{"location":"essentials/terminal_diagnostics/#deep-dives","title":"Deep Dives","text":"<ul> <li>Operating System Scheduling - How the OS decides which process gets CPU time.</li> <li>The Virtual Filesystem - How Linux presents system state as files in <code>/proc</code>.</li> </ul>"},{"location":"essentials/vim_survival_mode/","title":"Vim Survival Mode","text":"<p>You're SSH'd into a production server. You need to fix a critical config error. You type <code>vi config.yaml</code> and suddenly you're in a world where the arrow keys don't work quite right, and you can't even figure out how to type. Don't panic.</p> <p>Vim is a ubiquitous text editor available on almost every Unix-like system. While it has a legendary learning curve, SREs only need a handful of commands to be dangerous. This is \"Survival Mode\"\u2014the bare essentials to get in, fix the problem, and get out.</p>"},{"location":"essentials/vim_survival_mode/#the-most-important-rule-modal-editing","title":"The Most Important Rule: Modal Editing","text":"<p>Vim is not like Notepad or VS Code. It is modal. It has different \"modes\" for different tasks.</p> <pre><code>graph LR\n    N[Normal Mode] -- \"i\" --&gt; I[Insert Mode]\n    I -- \"Esc\" --&gt; N\n    N -- \":\" --&gt; C[Command Mode]\n    C -- \"Enter/Esc\" --&gt; N\n    N -- \"v\" --&gt; V[Visual Mode]\n    V -- \"Esc\" --&gt; N</code></pre> <ol> <li>Normal Mode: For moving around and deleting text. This is the default.</li> <li>Insert Mode: For actually typing text.</li> <li>Command Mode: For saving, quitting, and other editor-wide actions.</li> </ol>"},{"location":"essentials/vim_survival_mode/#quick-start-get-productive-in-5-minutes","title":"Quick Start: Get Productive in 5 Minutes","text":"<p>If you remember nothing else, remember these four steps:</p> <ol> <li>Get in: <code>vi &lt;filename&gt;</code></li> <li>Type stuff: Press <code>i</code> (to enter Insert Mode), then type your changes.</li> <li>Stop typing: Press <code>Esc</code> (to return to Normal Mode).</li> <li>Get out: Type <code>:wq</code> and press <code>Enter</code> to save and quit. (Or <code>:q!</code> to quit without saving).</li> </ol>"},{"location":"essentials/vim_survival_mode/#essential-motions","title":"Essential Motions","text":"<p>In Normal Mode, your keyboard becomes a navigation tool.</p> <ul> <li> <p> Basic Navigation</p> <p>Why it matters: You can move faster than using arrow keys (which might not even work in some terminal configurations).</p> <ul> <li><code>h</code> (left), <code>j</code> (down), <code>k</code> (up), <code>l</code> (right)</li> <li><code>w</code>: Move forward one word</li> <li><code>b</code>: Move back one word</li> </ul> </li> <li> <p> Jumping Around</p> <p>Why it matters: Useful for large config files or long logs.</p> <ul> <li><code>gg</code>: Go to the top of the file</li> <li><code>G</code>: Go to the bottom of the file</li> <li><code>0</code>: Go to start of line</li> <li><code>$</code>: Go to end of line</li> </ul> </li> <li> <p> Quick Edits</p> <p>Why it matters: Fixing mistakes without entering Insert Mode.</p> <ul> <li><code>x</code>: Delete a single character</li> <li><code>dd</code>: Delete the entire line</li> <li><code>u</code>: Undo the last change</li> </ul> </li> </ul>"},{"location":"essentials/vim_survival_mode/#why-vim-matters-for-platform-work","title":"Why Vim Matters for Platform Work","text":"<p>As an SRE, you often work on \"headless\" systems (no GUI) or remote servers via SSH. Vim is the one tool you can guarantee will be there. Mastering survival mode means you're never \"stuck\" in a terminal environment.</p>"},{"location":"essentials/vim_survival_mode/#common-scenarios","title":"Common Scenarios","text":"Hotfix in Production Searching Logs Copy/Paste (Vim Style) <ol> <li><code>vi /etc/nginx/nginx.conf</code></li> <li><code>/server_name</code> (Search for the config line)</li> <li><code>i</code> (Enter insert mode)</li> <li>Fix the typo</li> <li><code>Esc</code></li> <li><code>:wq</code> (Save and quit)</li> </ol> <p>When viewing a large file in Vim: - <code>/pattern</code>: Search forward for \"pattern\" - <code>?pattern</code>: Search backward - <code>n</code>: Go to the next match - <code>N</code>: Go to the previous match</p> <ul> <li><code>yy</code>: \"Yank\" (copy) a line</li> <li><code>p</code>: \"Put\" (paste) after the cursor</li> <li><code>P</code>: \"Put\" (paste) before the cursor</li> </ul>"},{"location":"essentials/vim_survival_mode/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Getting Unstuck <p>You've typed a bunch of random keys and now Vim is beeping at you and showing weird symbols. How do you get back to a clean state where you can quit?</p> Answer <p>Press <code>Esc</code> multiple times. This ensures you are in Normal Mode. From there, you can type <code>:q!</code> to quit without saving any of the accidental changes you might have made.</p> Practice Problem 2: Deleting Text <p>You need to remove 5 lines of a config file. What's the fastest way to do it in Normal Mode?</p> Answer <p>Type <code>5dd</code>. In Vim, many commands can be preceded by a number to repeat the action that many times. <code>dd</code> deletes a line, so <code>5dd</code> deletes five.</p>"},{"location":"essentials/vim_survival_mode/#key-takeaways","title":"Key Takeaways","text":"Key Action <code>i</code> Enter Insert Mode <code>Esc</code> Return to Normal Mode <code>:w</code> Write (Save) the file <code>:q</code> Quit <code>:wq</code> Save and Quit <code>:q!</code> Quit without saving <code>/text</code> Search for \"text\""},{"location":"essentials/vim_survival_mode/#further-reading","title":"Further Reading","text":""},{"location":"essentials/vim_survival_mode/#official-documentation","title":"Official Documentation","text":"<ul> <li><code>vimtutor</code> - Run this command in your terminal for an interactive 15-minute tutorial.</li> <li>Vim Help - Online version of Vim's internal documentation.</li> </ul>"},{"location":"essentials/vim_survival_mode/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>NeoVim - A modern fork of Vim with better defaults and extensibility.</li> <li>Nano - A simpler, non-modal terminal editor (but not always installed).</li> </ul>"},{"location":"essentials/vim_survival_mode/#deep-dives","title":"Deep Dives","text":"<ul> <li>Vim Adventures - A game that teaches Vim motions.</li> <li>Modal Editing Philosophy - Why separating navigation from editing is a powerful abstraction.</li> </ul>"},{"location":"essentials/yq_wrangling_yaml/","title":"YQ: Wrangling YAML Configs","text":"<p>Kubernetes manifests, Ansible playbooks, GitHub Actions, Docker Compose\u2014in modern platform engineering, YAML is everywhere. But YAML's indentation-sensitive nature makes it notoriously difficult to edit with standard text tools like <code>sed</code> or <code>awk</code>.</p> <p><code>yq</code> is a portable command-line YAML processor. It's essentially <code>jq</code> for YAML, allowing you to slice, dice, and transform configuration files with precision and safety.</p>"},{"location":"essentials/yq_wrangling_yaml/#quick-start-get-productive-in-5-minutes","title":"Quick Start: Get Productive in 5 Minutes","text":"<p><code>yq</code> syntax is intentionally similar to <code>jq</code>. If you know one, you're halfway to knowing the other.</p> Common YQ Operations<pre><code># Read a specific value from a K8s manifest\nyq '.metadata.name' pod.yaml\n\n# Update a value in-place\nyq -i '.spec.replicas = 3' deployment.yaml\n\n# Convert YAML to JSON (perfect for piping to jq)\nyq -o=json '.' config.yaml\n\n# Merge two YAML files\nyq eval-all 'select(fileIndex == 0) * select(fileIndex == 1)' base.yaml overlay.yaml\n</code></pre>"},{"location":"essentials/yq_wrangling_yaml/#why-yq-matters-for-platform-work","title":"Why YQ Matters for Platform Work","text":"<p>YAML is the backbone of Infrastructure as Code (IaC). One wrong indentation can break a production deployment. <code>yq</code> removes this friction by treating YAML as a structured data format rather than a text file.</p>"},{"location":"essentials/yq_wrangling_yaml/#common-scenarios","title":"Common Scenarios","text":"K8s Manifest Auditing CI/CD Pipeline Updates Config Transformation <p>Find all containers in a Deployment that don't have resource limits defined:</p> Audit Resource Limits<pre><code>yq '.spec.template.spec.containers[] | select(has(\"resources\") | not) | .name' deployment.yaml\n</code></pre> <p>Update the image tag across multiple GitHub Action workflow files:</p> Update Image Tag<pre><code>yq -i '.jobs.build.steps[] | select(.uses == \"docker/build-push-action*\") | .with.tags = \"v2.1.0\"' .github/workflows/*.yml\n</code></pre> <p>Extract values from a legacy config and format them for a new system:</p> Extract and Format<pre><code>yq '.database | {host: .addr, port: .port}' old-config.yaml\n</code></pre>"},{"location":"essentials/yq_wrangling_yaml/#core-functionality","title":"Core Functionality","text":"<ul> <li> <p> In-place Editing (<code>-i</code>)</p> <p>Why it matters: Allows you to modify files directly without temporary files or redirects.</p> Update Config<pre><code>yq -i '.debug = true' config.yaml\n</code></pre> <p>Key insight: Always verify your filter without <code>-i</code> first!</p> </li> <li> <p> Multi-document Handling</p> <p>Why it matters: Kubernetes files often contain multiple documents separated by <code>---</code>.</p> Read All Documents<pre><code>yq '.. | select(has(\"kind\")) | .kind' multi.yaml\n</code></pre> <p>Key insight: <code>yq</code> handles the stream of documents automatically.</p> </li> <li> <p> Format Conversion (<code>-o</code>)</p> <p>Why it matters: Sometimes you need JSON for a tool that doesn't speak YAML.</p> YAML to JSON<pre><code>yq -o=json '.' service.yaml\n</code></pre> <p>Key insight: Useful for interoperability between different CLI tools.</p> </li> </ul>"},{"location":"essentials/yq_wrangling_yaml/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Navigating Lists <p>In a YAML file like <code>{\"items\": [{\"name\": \"a\", \"val\": 1}, {\"name\": \"b\", \"val\": 2}]}</code>, how do you get the value (<code>val</code>) for the item named \"b\"?</p> Answer <p><pre><code>yq '.items[] | select(.name == \"b\") | .val' file.yaml\n</code></pre> This iterates through the list, filters for the specific name, and then selects the desired field.</p> Practice Problem 2: Adding a Field <p>How would you add a <code>labels</code> object with <code>app: my-app</code> to the <code>metadata</code> of a YAML file?</p> Answer <p><pre><code>yq '.metadata.labels.app = \"my-app\"' file.yaml\n</code></pre> <code>yq</code> will automatically create the parent objects (<code>labels</code>) if they don't exist.</p>"},{"location":"essentials/yq_wrangling_yaml/#key-takeaways","title":"Key Takeaways","text":"Feature command/Filter Read <code>yq '.path.to.key' file.yaml</code> Write <code>yq -i '.key = \"value\"' file.yaml</code> Filter <code>select(.key == \"match\")</code> Convert <code>-o=json</code> (to JSON), <code>-o=xml</code> (to XML) Delete <code>del(.key.to.remove)</code>"},{"location":"essentials/yq_wrangling_yaml/#further-reading","title":"Further Reading","text":""},{"location":"essentials/yq_wrangling_yaml/#official-documentation","title":"Official Documentation","text":"<ul> <li>YQ Documentation - Comprehensive guide for the most popular <code>yq</code> implementation (mikefarah).</li> <li>YQ GitHub Repository - Source code and community discussions.</li> </ul>"},{"location":"essentials/yq_wrangling_yaml/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>jq - The JSON processor that inspired <code>yq</code>.</li> <li>yamllint - For validating YAML syntax and style.</li> </ul>"},{"location":"essentials/yq_wrangling_yaml/#deep-dives","title":"Deep Dives","text":"<ul> <li>YAML Specification - For when you really need to understand why your indentation is broken.</li> <li>Parsing and Serialization - Theoretical background on how structured data is handled.</li> </ul>"},{"location":"essentials/git/git_basics/","title":"Git Basics - Your First Repository","text":"<p>Part of Git Essentials Series</p> <p>This is article 1 of the Git Essentials series. After mastering local repositories here, continue to Git Collaboration to learn remote repositories and teamwork.</p> <p>You're managing three versions of the same backup script: <code>backup.sh</code>, <code>backup_v2.sh</code>, and <code>backup_FINAL_USE_THIS_ONE.sh</code>. Last week, someone ran the wrong version in production. You spent an hour figuring out which one was actually deployed. This is why professional engineers use version control.</p> <p>Whether you're writing BASH scripts, Python automation, Perl utilities, or managing infrastructure as code (Terraform, Ansible, Kubernetes manifests), version control is the difference between amateur hour and professional engineering.</p>"},{"location":"essentials/git/git_basics/#what-git-is-and-why-you-need-it","title":"What Git Is (And Why You Need It)","text":"<p>Git is a distributed version control system. In plain English: it tracks every change you make to your files, who made it, when, and why. Think of it as an unlimited undo button combined with a time machine for your code.</p> <p>Under the hood, Git manages these changes as a Directed Acyclic Graph (DAG) of commits. Each commit points to its parent(s), creating a verifiable history that never loses data. You can learn more about how trees and graph structures work on our computer science fundamentals site.</p> <p>For platform engineers, Git solves real problems:</p> <ul> <li>No more file versioning chaos: One file, complete history, no <code>script_v2_final.sh</code> madness</li> <li>Collaboration without conflicts: Multiple people can work on the same scripts without overwriting each other</li> <li>Audit trail: Know exactly who changed what configuration and when (critical for compliance and incident response)</li> <li>Safe experimentation: Try changes in isolation, roll back if they break production</li> <li>Sharing and backup: Your code lives on remote servers (GitHub, GitLab), not just your laptop</li> </ul>"},{"location":"essentials/git/git_basics/#quick-start-your-first-repository","title":"Quick Start: Your First Repository","text":"<p>Let's get you productive in 5 minutes. We'll version control a script you're already working on.</p>"},{"location":"essentials/git/git_basics/#installation","title":"Installation","text":"Linux macOS Windows Install Git on Linux<pre><code># Debian/Ubuntu\nsudo apt update &amp;&amp; sudo apt install git\n\n# RHEL/Fedora/CentOS\nsudo dnf install git\n</code></pre> Install Git on macOS<pre><code># Using Homebrew\nbrew install git\n\n# Or use Xcode Command Line Tools\nxcode-select --install\n</code></pre> <p>Choose your approach based on your workflow:</p>  Git for Windows (Recommended) WSL2 (Linux Subsystem) <p>Best for: Working primarily on Windows, deploying to Linux servers</p> <ol> <li>Download from git-scm.com</li> <li> <p>Run the installer with these critical settings:</p> <ul> <li>Default editor: Choose VS Code, Vim, or Nano (NOT Notepad)</li> <li>PATH environment: \"Git from the command line and also from 3rd-party software\"</li> <li>Line ending conversions: \"Checkout as-is, commit Unix-style line endings\" (1)</li> <li>Terminal emulator: Use MinTTY (Git Bash) or Windows Terminal</li> <li>Credential helper: Git Credential Manager (enables GitHub/GitLab auth)</li> </ul> </li> <li> <p>After installation, use Git Bash for Unix-like commands or PowerShell if you prefer Windows-native tools.</p> </li> </ol> <p>Critical post-installation configuration:</p> Configure Line Endings<pre><code>git config --global core.autocrlf input  # (2)!\n</code></pre> <ol> <li>Line ending settings matter! Windows uses CRLF (<code>\\r\\n</code>), Linux/macOS use LF (<code>\\n</code>). Wrong settings cause spurious diffs and break shell scripts when deployed to Linux servers. \"Checkout as-is, commit Unix-style\" ensures scripts work on Linux.</li> <li><code>core.autocrlf input</code> means: leave files alone when checking out, but convert CRLF to LF when committing. This prevents Windows line endings from breaking scripts on Linux servers.</li> </ol> <p>Best for: Managing Linux infrastructure from Windows, need native Linux tools</p> Install WSL2 and Git<pre><code># In PowerShell (as Administrator)\nwsl --install -d Ubuntu\n\n# Inside WSL2 Ubuntu terminal\nsudo apt update &amp;&amp; sudo apt install git\n</code></pre> <p>Why WSL2:</p> <ul> <li>Native Linux Git behavior (no line ending issues)</li> <li>Access to Linux-native tools (<code>bash</code>, <code>ssh</code>, <code>grep</code>, etc.)</li> <li>Same commands as your production Linux servers</li> <li>Can edit files with Windows tools, commit with Linux Git</li> </ul>"},{"location":"essentials/git/git_basics/#configure-git-one-time-setup","title":"Configure Git (One-Time Setup)","text":"<p>Git needs to know who you are so it can attribute changes correctly:</p> Configure Your Identity<pre><code>git config --global user.name \"Your Name\"  # (1)!\ngit config --global user.email \"you@example.com\"  # (2)!\n</code></pre> <ol> <li>Your name appears in commit history - use your real name for professional work</li> <li>Your email links commits to your GitHub/GitLab account</li> </ol>"},{"location":"essentials/git/git_basics/#create-your-first-repository","title":"Create Your First Repository","text":"<p>Let's version control an existing script:</p> Initialize a Git Repository<pre><code>cd ~/scripts  # (1)!\ngit init  # (2)!\ngit add backup.sh  # (3)!\ngit commit -m \"Initial commit: backup script v1\"  # (4)!\n</code></pre> <ol> <li>Navigate to your scripts directory</li> <li>Initialize Git - creates a <code>.git</code> folder to track history</li> <li>Stage the file - tell Git you want to track this file</li> <li>Commit - save a snapshot with a descriptive message</li> </ol> <p>Congratulations! You just created your first Git repository. Your script is now version controlled.</p>"},{"location":"essentials/git/git_basics/#understanding-what-just-happened-the-three-states","title":"Understanding What Just Happened: The Three States","text":"<p>You just ran <code>git add</code> and then <code>git commit</code>, but why two commands? Why not just one \"save\" command like every other tool you use?</p> <p>This is where Git is different - and understanding why makes you dangerous (in a good way). Git moves files through three distinct states, giving you precise control over what gets saved and when. This isn't complexity for complexity's sake - it's what lets you stage related changes together, review before committing, and maintain a clean history.</p> <p>What you just did:</p> <ol> <li><code>git add backup.sh</code> - Moved the file from Modified to Staged (marked it for inclusion)</li> <li><code>git commit</code> - Moved it from Staged to Committed (permanently saved in history)</li> </ol> <p>Let's understand these states properly:</p> <pre><code>graph TD\n    A[Modified&lt;br/&gt;Changes in working directory] --&gt;|git add| B[Staged&lt;br/&gt;Changes ready to commit]\n    B --&gt;|git commit| C[Committed&lt;br/&gt;Saved in repository history]\n    C -.-&gt;|git checkout| A\n\n    style A fill:#c53030,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style B fill:#d69e2e,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style C fill:#2f855a,stroke:#cbd5e0,stroke-width:2px,color:#fff</code></pre> <ul> <li> <p> Modified</p> <p>What it means: You've changed a file but haven't told Git about it yet.</p> See Modified Files<pre><code>git status  # Shows modified files in red\n</code></pre> <p>In your workflow: You're editing <code>deploy.sh</code> and making changes locally.</p> </li> <li> <p> Staged</p> <p>What it means: You've marked changes to be included in the next commit.</p> Stage Files<pre><code>git add deploy.sh  # Stage specific file\ngit add .  # Stage all changes (use carefully!)\n</code></pre> <p>In your workflow: You've finished editing and you're ready to save a snapshot.</p> </li> <li> <p> Committed</p> <p>What it means: Changes are permanently saved in Git's history.</p> Commit Changes<pre><code>git commit -m \"Add error handling to deploy script\"\n</code></pre> <p>In your workflow: This version is saved forever. You can always return to it.</p> </li> </ul>"},{"location":"essentials/git/git_basics/#common-scenarios-for-platform-engineers","title":"Common Scenarios for Platform Engineers","text":"<p>Let's walk through real situations you'll encounter daily.</p>  Tracking Script Changes Undoing Mistakes Viewing History <p>You maintain a collection of operational scripts. Version control them properly:</p> Version Control Your Scripts<pre><code>cd ~/ops-scripts\ngit init\n\n# Add scripts one at a time (safer than git add .)\ngit add backup.sh\ngit add deploy.sh\ngit add cleanup.sh\n\ngit commit -m \"Initial commit: core ops scripts\"\n</code></pre> <p>Why per-file staging matters: You might have test files, credentials, or temporary scripts you don't want to commit.</p> <p>You made changes and broke the script. Git provides safety nets:</p> Undo Commands<pre><code># Discard local changes (before staging)\ngit restore backup.sh  # (1)!\n\n# Unstage a file (oops, didn't mean to add that!)\ngit restore --staged secret.env  # (2)!\n\n# Change the last commit message\ngit commit --amend -m \"Better message\"  # (3)!\n\n# Undo the last commit but keep changes\ngit reset --soft HEAD~1  # (4)!\n</code></pre> <ol> <li>Throw away local edits, go back to last committed version</li> <li>Remove file from staging area but keep your local changes</li> <li>Modify the most recent commit (message or add more files)</li> <li>Uncommit but keep files in staging area - useful if you committed too early</li> </ol> <p>Who changed the firewall rules last Tuesday? Git knows:</p> Investigate History<pre><code># See recent commits\ngit log  # (1)!\n\n# See what changed in each commit\ngit log -p  # (2)!\n\n# See who wrote each line of a file\ngit blame firewall-rules.sh  # (3)!\n\n# Search commit messages\ngit log --grep=\"firewall\"  # (4)!\n</code></pre> <ol> <li>Shows commit history with messages, authors, dates</li> <li>Shows actual code changes in each commit</li> <li>Line-by-line attribution - most useful when working with teammates (we'll cover this more in Git Collaboration)</li> <li>Find commits mentioning \"firewall\" - great for incident investigation</li> </ol>"},{"location":"essentials/git/git_basics/#avoiding-common-pitfalls","title":"Avoiding Common Pitfalls","text":"<ul> <li> <p> Never Commit Secrets</p> <p>The problem: Credentials, API keys, and passwords in Git history are a security nightmare.</p> <p>The solution: Use <code>.gitignore</code> to prevent secret files from being tracked.</p> Add to .gitignore<pre><code># Secrets and credentials\n.env\n*.pem\n*.key\ncredentials.json\nconfig/secrets.yml\n</code></pre> <p>Why this matters: Once committed, secrets are in history forever (even if you delete the file later). Use <code>.gitignore</code> BEFORE you commit.</p> </li> <li> <p> Write Meaningful Commit Messages</p> <p>The problem: \"Fixed stuff\" doesn't help anyone (including future you).</p> Good Commit Message Example<pre><code>feat: add retry logic to backup script\n\nAdded 3 retry attempts with exponential backoff\nwhen S3 upload fails. Prevents backup failures\nduring temporary network issues.\n\nResolves ticket OPS-1234\n</code></pre> <p>The format: First line = summary (50 chars max). Body = why you made this change.</p> </li> <li> <p> Use .gitignore Strategically</p> <p>The problem: You don't want temporary files, logs, or build artifacts in version control.</p> .gitignore Example<pre><code># Python\n__pycache__/\n*.pyc\n.venv/\n\n# Terraform\n.terraform/\n*.tfstate\n*.tfstate.backup\n\n# Secrets\n.env\n*.pem\ncredentials.json\n\n# Logs\n*.log\n</code></pre> <p>Key insight: If it's generated, temporary, or secret, it doesn't belong in Git.</p> </li> </ul>"},{"location":"essentials/git/git_basics/#whats-next-collaborating-with-git","title":"What's Next: Collaborating with Git","text":"<p>You now know how to manage a local Git repository - tracking changes, viewing history, and undoing mistakes. But professional platform engineering is a team sport.</p> <p>Continue to Git Collaboration to learn:</p> <ul> <li>Remote repositories (GitHub, GitLab)</li> <li>Clone, pull, push workflows</li> <li>Daily team collaboration</li> <li>Handling basic conflicts</li> </ul>"},{"location":"essentials/git/git_basics/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Undoing Staged Changes <p>You accidentally ran <code>git add .</code> and included a file named <code>database_password.txt</code>. The file is now staged. How do you remove it from the staging area WITHOUT deleting the file from your disk?</p> Answer <pre><code>git restore --staged database_password.txt\n</code></pre> <p>This moves the file from Staged back to Modified state. The file remains on disk, but Git won't include it in the next commit. You should immediately add it to <code>.gitignore</code>.</p> Practice Problem 2: Viewing History <p>Someone changed the backup script last week and it's been failing ever since. How do you find out who changed it and what they modified?</p> Answer <pre><code># See recent commits for this file\ngit log backup.sh\n\n# See the actual changes\ngit log -p backup.sh\n\n# See line-by-line attribution\ngit blame backup.sh\n</code></pre> <p><code>git log</code> shows who committed what and when. <code>git log -p</code> shows the actual code changes. <code>git blame</code> shows who wrote each line currently in the file (most useful for team collaboration - covered in detail in Git Collaboration).</p> Practice Problem 3: Undoing a Committed Change <p>You committed a change to <code>cleanup.sh</code>, but it's causing problems. You haven't pushed it yet. How do you undo the commit but keep your file changes so you can fix them?</p> Answer <pre><code>git reset --soft HEAD~1\n</code></pre> <p>This undoes the most recent commit but leaves your changes in the staging area. You can now edit the file, fix the problem, and commit again. Use <code>--soft</code> to keep changes staged, or <code>--mixed</code> to unstage them (but still keep file changes).</p>"},{"location":"essentials/git/git_basics/#key-takeaways","title":"Key Takeaways","text":"Concept What It Means Why It Matters Repository A project tracked by Git (the <code>.git</code> folder) Your scripts/configs have complete history Modified Changed files in working directory Unsaved edits - you're still working Staged Files marked for the next commit Precise control over what gets saved Committed Permanently saved in Git history Safe snapshot you can always return to Remote Repository on GitHub/GitLab/etc Collaboration and backup Clone Download a repository copy Get teammates' code with full history Pull Get latest changes from remote Stay in sync with team Push Send your commits to remote Share your work with team"},{"location":"essentials/git/git_basics/#quick-reference","title":"Quick Reference","text":"Essential Git Commands<pre><code># Setup\ngit config --global user.name \"Name\"\ngit config --global user.email \"email\"\n\n# Start tracking\ngit init                          # Create new repository\ngit clone &lt;url&gt;                   # Copy existing repository\n\n# Daily workflow\ngit status                        # See what's changed\ngit diff                          # See changes in detail\ngit add &lt;file&gt;                    # Stage changes\ngit commit -m \"message\"           # Save snapshot\ngit log                           # View history\n\n# Undo mistakes\ngit restore &lt;file&gt;                # Discard local changes\ngit restore --staged &lt;file&gt;       # Unstage\ngit commit --amend                # Fix last commit\ngit reset --soft HEAD~1           # Undo last commit, keep changes\n\n# Collaboration\ngit pull origin main              # Get latest changes\ngit push origin main              # Share your changes\ngit remote -v                     # See remote repositories\n</code></pre>"},{"location":"essentials/git/git_basics/#further-reading","title":"Further Reading","text":""},{"location":"essentials/git/git_basics/#official-documentation","title":"Official Documentation","text":"<ul> <li>Pro Git Book - The comprehensive Git reference, free online</li> <li>Git Documentation - Official docs and command reference</li> </ul>"},{"location":"essentials/git/git_basics/#related-tools-workflows","title":"Related Tools &amp; Workflows","text":"<ul> <li>GitHub Flow - Simple branch-based workflow for teams</li> <li>Pre-commit Hooks - Automate checks before commits (linting, security scans)</li> </ul>"},{"location":"essentials/git/git_basics/#deep-dives","title":"Deep Dives","text":"<ul> <li>Git Workflows (coming soon) - Feature branches, pull requests, conflict resolution</li> <li>Git Internals (coming soon) - How Git actually works under the hood</li> </ul>"},{"location":"essentials/git/git_basics/#platform-engineering-context","title":"Platform Engineering Context","text":"<ul> <li>Infrastructure as Code Best Practices - Why version control matters for IaC</li> <li>The Twelve-Factor App - Modern app/platform engineering principles (includes version control)</li> </ul> <p>What's Next: Once you're comfortable with basic Git, continue to Git Collaboration to learn how to work with remote repositories, sync with your team, and use branch-based workflows professionally.</p>"},{"location":"essentials/git/git_collaboration/","title":"Git Collaboration - Working with Remote Repositories","text":"<p>Part of Git Essentials Series</p> <p>This is article 2 of the Git Essentials series. If you haven't mastered local repositories yet, start with Git Basics first.</p> <p>Your teammate just shared a repository link: \"Here's the monitoring scripts repo - clone it and add your disk space check.\" You stare at the URL. Clone? Where does the code even go? How do you get your changes back to the team?</p> <p>This is the reality of professional platform engineering - your scripts and infrastructure code live on shared repositories (GitHub, GitLab, Bitbucket), not just your laptop. Collaboration isn't optional; it's how the job works.</p>"},{"location":"essentials/git/git_collaboration/#what-are-remote-repositories","title":"What Are Remote Repositories?","text":"<p>A remote repository is a version of your project hosted on a server (GitHub, GitLab, your company's Git server). Think of it as the \"source of truth\" that your team syncs with.</p> <p>Why remote repositories matter for platform engineers:</p> <ul> <li>Collaboration - Multiple people can work on the same scripts/infrastructure code</li> <li>Backup - Your code exists on a server, not just your laptop</li> <li>Code review - Teammates can review changes before they go to production</li> <li>CI/CD integration - Automated testing and deployment when you push code</li> <li>Audit trail - Complete history of who changed what and when</li> </ul> <p>The workflow:</p> <pre><code>graph TD\n    A[Remote Repository&lt;br/&gt;GitHub/GitLab] --&gt;|git clone| B[Your Local Copy]\n    B --&gt;|git add + commit| C[Local Changes]\n    C --&gt;|git push| A\n    A --&gt;|git pull| B\n\n    style A fill:#2f855a,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style B fill:#2d3748,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style C fill:#d69e2e,stroke:#cbd5e0,stroke-width:2px,color:#fff</code></pre>"},{"location":"essentials/git/git_collaboration/#getting-started-two-common-scenarios","title":"Getting Started: Two Common Scenarios","text":"<p>Platform engineers encounter two main scenarios with remote repositories:</p>  Joining an Existing Project Sharing Your Own Scripts <p>The situation: Your team already has a repository with scripts/configs. You need to get the code and start contributing.</p> <p>What you do: Clone the repository to get a local copy.</p> Clone an Existing Repository<pre><code>git clone git@github.com:company/ops-scripts.git  # (1)!\ncd ops-scripts  # (2)!\nls -la  # (3)!\n</code></pre> <ol> <li>Downloads the entire repository including all history</li> <li>Navigate into the cloned directory</li> <li>See all the files - you now have a complete working copy</li> </ol> <p>Key insight: <code>clone</code> creates a new directory with the repository name. You get everything: files, history, branches.</p> <p>The situation: You've been working on scripts locally (using Git Basics). Now you want to share them with your team.</p> <p>What you do: Create a remote repository and push your local work to it.</p> Push Local Repository to Remote<pre><code># (After creating repo on GitHub/GitLab)\ngit remote add origin git@github.com:you/monitoring-scripts.git  # (1)!\ngit branch -M main  # (2)!\ngit push -u origin main  # (3)!\n</code></pre> <ol> <li>Link your local repo to the remote repository</li> <li>Ensure your branch is named \"main\" (modern convention)</li> <li>Push your code and set upstream tracking (initial push only - see warning below)</li> </ol> <p>After This Initial Push</p> <p>This is a one-time setup to get your code on the remote. Once teammates join, always work on branches and use pull requests to merge to <code>main</code>. See the Daily Collaboration Workflow section below.</p>"},{"location":"essentials/git/git_collaboration/#understanding-clone-pull-and-push","title":"Understanding Clone, Pull, and Push","text":"<p>Three commands control collaboration:</p> Command Direction What It Does When You Use It <code>git clone</code> Remote \u2192 Local Downloads entire repository for first time Joining a new project <code>git pull</code> Remote \u2192 Local Updates your local copy with team's changes Morning sync, before starting work <code>git push</code> Local \u2192 Remote Sends your commits to the remote Sharing your completed work"},{"location":"essentials/git/git_collaboration/#setting-up-remote-repositories","title":"Setting Up Remote Repositories","text":"GitHub GitLab Company Git Server <p>Step 1: Create repository on GitHub</p> <ol> <li>Go to github.com and click \"New repository\"</li> <li>Name it (e.g., <code>ops-scripts</code>)</li> <li>Choose public or private</li> <li>Don't initialize with README (you already have local commits)</li> <li>Click \"Create repository\"</li> </ol> <p>Step 2: Link your local repository</p> Connect to GitHub<pre><code>git remote add origin git@github.com:username/ops-scripts.git\ngit push -u origin main\n</code></pre> <p>SSH vs HTTPS: Use SSH URLs (<code>git@github.com:...</code>) for passwordless authentication with SSH keys. HTTPS URLs require credentials every push.</p> <p>Step 1: Create project on GitLab</p> <ol> <li>Go to gitlab.com and click \"New project\"</li> <li>Choose \"Create blank project\"</li> <li>Name it and set visibility (public/private)</li> <li>Uncheck \"Initialize repository with a README\"</li> <li>Click \"Create project\"</li> </ol> <p>Step 2: Link your local repository</p> Connect to GitLab<pre><code>git remote add origin git@gitlab.com:username/ops-scripts.git\ngit push -u origin main\n</code></pre> <p>Your company likely has:</p> <ul> <li>GitHub Enterprise (self-hosted GitHub)</li> <li>Self-hosted GitLab</li> <li>Bitbucket Server</li> <li>Azure DevOps Repos</li> <li>AWS CodeCommit</li> </ul> <p>The process is the same:</p> Connect to Company Git Server<pre><code># GitHub Enterprise\ngit remote add origin git@github.company.com:team/ops-scripts.git\n\n# Or other company Git server\ngit remote add origin git@git.company.com:team/ops-scripts.git\n\ngit push -u origin main\n</code></pre> <p>Ask your team: What's the Git server URL? Do you need VPN access? Are there naming conventions?</p>"},{"location":"essentials/git/git_collaboration/#daily-collaboration-workflow","title":"Daily Collaboration Workflow","text":"<p>Professional collaboration with Git follows a rhythm: sync main, create branch, work, commit, push branch. Here's the visual workflow:</p> <pre><code>graph TD\n    A[Sync main&lt;br/&gt;git pull origin main] --&gt; B[Create your branch&lt;br/&gt;git checkout -b feature/name]\n    B --&gt; C[Work and commit&lt;br/&gt;Edit files, git add, git commit]\n    C --&gt; D[Push your branch&lt;br/&gt;git push origin feature/name]\n    D --&gt; E[Open Pull Request&lt;br/&gt;On GitHub/GitLab]\n    E --&gt; F[Code Review&lt;br/&gt;Teammates review]\n    F --&gt; G[Merge to main&lt;br/&gt;PR approved and merged]\n    G -.-&gt; A\n\n    style A fill:#2d3748,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style B fill:#2d3748,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style C fill:#d69e2e,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style D fill:#2d3748,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style E fill:#4a5568,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style F fill:#4a5568,stroke:#cbd5e0,stroke-width:2px,color:#fff\n    style G fill:#2f855a,stroke:#cbd5e0,stroke-width:2px,color:#fff</code></pre> <p>Never Commit Directly to Main</p> <p>In professional environments, <code>main</code> is protected. You work on your own branch and merge to <code>main</code> via pull requests (covered in Git Workflows - coming soon). Direct commits to <code>main</code> are bad practice.</p>"},{"location":"essentials/git/git_collaboration/#morning-start-with-a-clean-sync","title":"Morning: Start with a Clean Sync","text":"<p>Before you touch any code, get the latest changes from your team and create a branch for your work.</p> Morning: Sync and Create Branch<pre><code>cd ~/ops-scripts\ngit checkout main  # (1)!\ngit pull origin main  # (2)!\ngit checkout -b feature/disk-monitoring  # (3)!\n</code></pre> <ol> <li>Switch to main branch</li> <li>Get latest changes from the team</li> <li>Create a new branch for your work (branch names often use <code>feature/</code>, <code>fix/</code>, or <code>chore/</code> prefixes)</li> </ol> <p>What happens: Git fetches commits from the remote and automatically merges them into your local branch. If there are no conflicts, you're ready to work. If there are conflicts, Git will tell you which files need manual resolution.</p> <p>Output you'll see:</p> <pre><code>remote: Counting objects: 5, done.\nremote: Compressing objects: 100% (3/3), done.\nUnpacking objects: 100% (5/5), done.\nFrom github.com:company/ops-scripts\n   abc1234..def5678  main       -&gt; origin/main\nUpdating abc1234..def5678\nFast-forward\n backup.sh | 10 +++++-----\n 1 file changed, 5 insertions(+), 5 deletions(-)\n</code></pre> <p>This tells you your teammate modified <code>backup.sh</code> with 5 changes.</p>"},{"location":"essentials/git/git_collaboration/#during-the-day-work-on-your-branch","title":"During the Day: Work on Your Branch","text":"<p>Now you can work on your changes. You're on your own branch (<code>feature/disk-monitoring</code>), so you can commit freely without affecting the team's <code>main</code> branch.</p> During the Day: Make Changes<pre><code># Verify you're on your branch\ngit branch  # (1)!\n\n# Work on your script\nvim disk_monitor.sh\n\n# Review, stage, and commit (same workflow as Git Basics)\ngit status  # (2)!\ngit diff disk_monitor.sh\ngit add disk_monitor.sh\ngit commit -m \"Add disk space monitoring with 80% threshold alert\"\n</code></pre> <ol> <li>Shows which branch you're on (should show <code>* feature/disk-monitoring</code>)</li> <li>Use the same review workflow from Git Basics - status, diff, add, commit</li> </ol> <p>Pro tip for teams: Commit more frequently than you would solo. Small, focused commits (\"Add monitoring function\" \u2192 \"Add threshold logic\" \u2192 \"Add alerts\") are easier for teammates to review than one giant \"Add disk monitoring\" commit.</p>"},{"location":"essentials/git/git_collaboration/#end-of-day-push-your-branch","title":"End of Day: Push Your Branch","text":"<p>When you're ready to share your work, push your branch to the remote repository. Your teammates can then review it via a pull request before it gets merged to <code>main</code>.</p> End of Day: Push Your Branch<pre><code>git push -u origin feature/disk-monitoring  # (1)!\n</code></pre> <ol> <li>Pushes your branch to the remote repository; <code>-u</code> sets up tracking so future pushes can use just <code>git push</code></li> </ol> <p>What happens next: After pushing your branch:</p> <ol> <li>Open a pull request on GitHub/GitLab/etc.</li> <li>Teammates review your code</li> <li>Once approved, the PR gets merged to <code>main</code></li> <li>You delete your branch and start a new one for the next task</li> </ol> <p>We'll cover pull requests in detail in Git Workflows** (coming soon) - for now, just know that pushing your branch is the first step toward getting your code into <code>main</code>.</p>"},{"location":"essentials/git/git_collaboration/#the-complete-daily-rhythm","title":"The Complete Daily Rhythm","text":"<p>Here's the full workflow on one screen:</p> Full Daily Git Workflow (Branch-Based)<pre><code># Morning: Sync main and create your branch\ngit checkout main\ngit pull origin main\ngit checkout -b feature/my-feature\n\n# During the day: Work and commit (repeat as needed)\nvim script.sh\ngit add script.sh\ngit commit -m \"Clear description of what changed\"\n\n# Before lunch/breaks: Push your branch (backup your work)\ngit push -u origin feature/my-feature\n\n# End of day: Push your branch\ngit push origin feature/my-feature\n# Then open a pull request on GitHub/GitLab\n</code></pre> <p>Key habits:</p> <ul> <li>Always work on a branch - Never commit directly to <code>main</code></li> <li>Sync main before creating branch - Start with the latest code</li> <li>Commit often - Small, focused commits are better</li> <li>Push your branch regularly - Backs up your work to the remote</li> <li>Clear commit messages - Your teammates (and future you) will thank you</li> <li>Use pull requests to merge to main - Covered in Git Workflows (coming soon)</li> </ul>"},{"location":"essentials/git/git_collaboration/#common-collaboration-patterns","title":"Common Collaboration Patterns","text":"The Morning Sync Checking Who Changed What Checking Remote Status Getting Specific Versions <p>Start every day with <code>git pull</code>:</p> Daily Standup Routine<pre><code>cd ~/infrastructure-repo\ngit pull origin main\n# Now you have the latest changes from overnight/other time zones\n</code></pre> <p>Why this matters: Prevents working on outdated code. You'll know immediately if teammates changed files you're planning to edit.</p> <p>Someone broke the deployment script. Who was it? Use the <code>git log</code> and <code>git blame</code> commands from Git Basics, but now for team investigation:</p> Investigate Team Changes<pre><code>git log --oneline -5           # Last 5 commits from anyone on the team\ngit log --author=\"jane\"        # Filter by teammate\ngit blame deploy.sh            # Who wrote each line currently in the file\n</code></pre> <p>Am I ahead or behind the team?</p> Check Sync Status<pre><code>git fetch origin  # (1)!\ngit status  # (2)!\n</code></pre> <ol> <li>Updates remote tracking info (doesn't change your files)</li> <li>Shows if you're ahead/behind/diverged from origin/main</li> </ol> <p>Example output: <pre><code>Your branch is ahead of 'origin/main' by 2 commits.\n  (use \"git push\" to publish your local commits)\n</code></pre></p> <p>Need the version from last week for rollback?</p> View and Checkout Old Versions<pre><code>git log --oneline  # (1)!\ngit checkout abc1234 -- deploy.sh  # (2)!\ngit diff deploy.sh  # (3)!\n</code></pre> <ol> <li>Find the commit hash from last week</li> <li>Get that specific version of the file</li> <li>See what changed between then and now</li> </ol>"},{"location":"essentials/git/git_collaboration/#understanding-remote-tracking","title":"Understanding Remote Tracking","text":"<p>When you clone or push with <code>-u</code>, Git sets up remote tracking:</p> See Remote Configuration<pre><code>git remote -v  # (1)!\n# origin  git@github.com:company/ops-scripts.git (fetch)\n# origin  git@github.com:company/ops-scripts.git (push)\n\ngit branch -vv  # (2)!\n# * main abc1234 [origin/main] Add monitoring script\n</code></pre> <ol> <li>Shows all remote repositories linked to your local repo</li> <li>Shows which remote branch your local branch tracks</li> </ol> <p>What <code>-u</code> does in <code>git push -u origin main</code>:</p> <ul> <li>Sets <code>origin/main</code> as the \"upstream\" for your local <code>main</code> branch</li> <li>After this, you can use just <code>git push</code> instead of <code>git push origin main</code></li> <li>Git knows where to push and pull from automatically</li> </ul>"},{"location":"essentials/git/git_collaboration/#avoiding-common-mistakes","title":"Avoiding Common Mistakes","text":"<ul> <li> <p> Don't Push Broken Code</p> <p>The problem: Pushing code that doesn't work breaks your teammates' environments.</p> <p>The solution: Test locally before pushing.</p> Pre-Push Checklist<pre><code># Run your script locally\n./monitoring.sh\n\n# Check syntax if it's code\npython -m py_compile script.py  # Python\nbash -n script.sh  # Bash\n\n# Then push\ngit push origin main\n</code></pre> </li> <li> <p> Don't Push Secrets</p> <p>Setup: Git Basics covers .gitignore configuration - set that up BEFORE pushing.</p> <p>Pre-push check: Once you're collaborating with a team, add this to your routine:</p> Pre-Push Secret Check<pre><code>git diff origin/main..HEAD  # What am I about to push?\ngrep -r \"password\\|secret\\|key\" .  # Scan for secrets\n</code></pre> <p>If you accidentally pushed secrets: Rotate the credentials immediately. Once in remote history, deletion doesn't help - teammates already pulled it.</p> </li> <li> <p> Always Pull Before Push</p> <p>The problem: If you push without pulling first and teammates changed the same files, you'll get rejected.</p> <p>Error you'll see: <pre><code>! [rejected]        main -&gt; main (non-fast-forward)\nerror: failed to push some refs\n</code></pre></p> <p>The fix: Sync Before Pushing<pre><code>git pull origin main  # Get teammate changes\n# Resolve any conflicts if needed\ngit push origin main  # Now push works\n</code></pre></p> </li> </ul>"},{"location":"essentials/git/git_collaboration/#when-things-go-wrong","title":"When Things Go Wrong","text":"<p>Scenario: \"I pulled and now there are conflicts\"</p> <p>You'll see: <pre><code>Auto-merging monitoring.sh\nCONFLICT (content): Merge conflict in monitoring.sh\nAutomatic merge failed; fix conflicts and then commit the result.\n</code></pre></p> <p>What this means: You and a teammate changed the same lines. Git can't automatically merge. This conflict often happens when multiple changes occur at the same level of Git's internal tree structure.</p> <p>Quick resolution (we'll cover this deeply in Git Efficiency):</p> <ol> <li>Open the file - Git marks conflicts with <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>, <code>=======</code>, <code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code></li> <li>Edit to keep the correct version (yours, theirs, or combination)</li> <li>Remove the conflict markers</li> <li><code>git add monitoring.sh</code></li> <li><code>git commit -m \"Merge remote changes\"</code></li> <li><code>git push origin main</code></li> </ol> <p>Scenario: \"I pushed and realized I made a mistake\"</p> <p>Option 1: Fix it with a new commit (recommended) <pre><code># Fix the mistake\nvim monitoring.sh\ngit add monitoring.sh\ngit commit -m \"Fix threshold logic in monitoring script\"\ngit push origin main\n</code></pre></p> <p>Option 2: Revert the commit (creates inverse commit) <pre><code>git log --oneline  # Find the bad commit hash\ngit revert abc1234  # Creates new commit that undoes it\ngit push origin main\n</code></pre></p> <p>Don't use <code>git push --force</code> - This can overwrite teammates' work. Only force-push if you absolutely know what you're doing and have coordinated with your team.</p>"},{"location":"essentials/git/git_collaboration/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Cloning and Exploring <p>You're joining a new team. They gave you the repository URL: <code>git@github.com:company/ansible-playbooks.git</code></p> <p>Tasks: 1. Clone the repository 2. List all files 3. See the last 5 commits 4. Find out who last modified <code>webserver.yml</code></p> Solution Clone and Explore Repository<pre><code># Clone the repo\ngit clone git@github.com:company/ansible-playbooks.git\ncd ansible-playbooks\n\n# List all files\nls -la\n\n# See last 5 commits\ngit log --oneline -5\n\n# Find who last modified webserver.yml\ngit log -1 webserver.yml\n# Or see line-by-line attribution:\ngit blame webserver.yml\n</code></pre> Practice Problem 2: Daily Workflow <p>You're working on a script called <code>backup.sh</code>. Your teammate just told you they pushed changes to <code>main</code> this morning.</p> <p>Tasks: 1. Sync main with the latest changes 2. Create a branch for your work 3. Make your changes to the file 4. Commit and push your branch</p> Solution Branch-Based Workflow<pre><code># Sync main with teammate's changes\ngit checkout main\ngit pull origin main\n\n# Create your branch\ngit checkout -b fix/backup-error-handling\n\n# Make your changes\nvim backup.sh\n\n# Check what you changed\ngit status\ngit diff backup.sh\n\n# Commit your changes to your branch\ngit add backup.sh\ngit commit -m \"Add error handling for S3 upload failures\"\n\n# Push your branch\ngit push -u origin fix/backup-error-handling\n# Next: Open a pull request to merge to main\n</code></pre> Practice Problem 3: Checking Remote Status <p>You've made 3 local commits but haven't pushed yet. You want to know: 1. Are you ahead or behind the remote? 2. What commits haven't been pushed yet?</p> Solution Check Remote Status<pre><code># Update remote tracking information\ngit fetch origin\n\n# Check status\ngit status\n# Output: \"Your branch is ahead of 'origin/main' by 3 commits\"\n\n# See which commits haven't been pushed\ngit log origin/main..HEAD\n# Shows your 3 local commits that aren't on the remote yet\n</code></pre>"},{"location":"essentials/git/git_collaboration/#key-takeaways","title":"Key Takeaways","text":"Concept Command When to Use Clone <code>git clone &lt;url&gt;</code> First time getting a repository Branch <code>git checkout -b feature/name</code> Create branch for your work Pull <code>git pull origin main</code> Sync main with team's latest changes Push <code>git push origin feature/name</code> Share your branch with team Remote <code>git remote -v</code> See configured remote repositories Fetch <code>git fetch origin</code> Update remote tracking (doesn't change files) Status <code>git status</code> Check if ahead/behind remote"},{"location":"essentials/git/git_collaboration/#quick-reference","title":"Quick Reference","text":"Essential Collaboration Commands<pre><code># Getting started\ngit clone &lt;url&gt;                   # Get a repository for first time\ngit remote -v                     # See remote repositories\n\n# Daily workflow (branch-based)\ngit checkout main                 # Switch to main\ngit pull origin main              # Get latest from team\ngit checkout -b feature/my-work   # Create your branch\ngit push -u origin feature/my-work # Push your branch\ngit fetch origin                  # Update remote info only\n\n# Checking status\ngit status                        # Am I ahead/behind?\ngit branch                        # Which branch am I on?\ngit log origin/main..HEAD         # What haven't I pushed?\n\n# Setting up remotes (initial setup only)\ngit remote add origin &lt;url&gt;       # Link to remote repository\ngit push -u origin main           # Initial push (then switch to branches)\n</code></pre>"},{"location":"essentials/git/git_collaboration/#further-reading","title":"Further Reading","text":""},{"location":"essentials/git/git_collaboration/#official-documentation","title":"Official Documentation","text":"<ul> <li>Pro Git: Working with Remotes - Comprehensive guide to remote repositories</li> <li>GitHub Docs: Getting Started - GitHub-specific workflows</li> </ul>"},{"location":"essentials/git/git_collaboration/#platform-specific-guides","title":"Platform-Specific Guides","text":"<ul> <li>GitHub Flow - Simple branch-based workflow</li> <li>GitLab Flow - GitLab's recommended workflow</li> <li>Atlassian Git Tutorials - Excellent collaboration guides</li> </ul>"},{"location":"essentials/git/git_collaboration/#team-collaboration","title":"Team Collaboration","text":"<ul> <li>Git Workflows (coming soon) - Advanced collaboration patterns (feature branches, pull requests)</li> <li>Code Review Best Practices - Google's code review guide</li> </ul>"},{"location":"essentials/git/git_collaboration/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Oh Shit, Git!?! - Common Git mistakes and how to fix them</li> <li>Git Flight Rules - What to do when things go wrong</li> </ul> <p>What's Next: You now know how to collaborate with Git. For advanced workflows like feature branches, pull requests, and conflict resolution, continue to Git Workflows (coming soon).</p>"},{"location":"mastery/advanced_shell/","title":"Advanced Shell: Functions, Aliases, and Logic","text":"<p>You're comfortable with <code>ls</code>, <code>cd</code>, and <code>grep</code>. You use <code>fzf</code> and <code>rg</code> to find things. But you still find yourself typing the same complex pipes over and over. This is where you move from using the shell to commanding it.</p> <p>Advanced shell usage is about building your own internal toolkit. By using functions, aliases, and logic, you can turn a 5-step manual process into a single, precise command.</p>"},{"location":"mastery/advanced_shell/#functions-vs-aliases","title":"Functions vs. Aliases","text":"<ul> <li> <p>:material-alias: Aliases</p> <p>Best for: Simple command replacements and adding default flags.</p> Essential Aliases<pre><code>alias k='kubectl'\nalias g='git'\nalias ls='eza --icons'\n</code></pre> <p>Key insight: Use aliases for \"shorthand.\"</p> </li> <li> <p> Functions</p> <p>Best for: Complex logic, accepting arguments, and multi-step pipes.</p> Pod Logs Function<pre><code>kl() {\n  kubectl logs -f $(kubectl get pods -o name | fzf)\n}\n</code></pre> <p>Key insight: Use functions for \"workflows.\"</p> </li> </ul>"},{"location":"mastery/advanced_shell/#quick-start-the-instant-value-functions","title":"Quick Start: The \"Instant Value\" Functions","text":"<p>Add these to your <code>~/.zshrc</code> or <code>~/.bashrc</code> to immediately improve your daily life.</p> Productivity Functions<pre><code># Create a directory and enter it immediately\nmkd() {\n  mkdir -p \"$1\" &amp;&amp; cd \"$1\"\n}\n\n# Find a file and open it in your editor\nfo() {\n  local file\n  file=$(fd --type f | fzf)\n  [ -n \"$file\" ] &amp;&amp; ${EDITOR:-vim} \"$file\"\n}\n\n# Search shell history and put the result on the command line\nfh() {\n  print -z $(history | fzf +s --tac | sed 's/^[ ]*[0-9]*[ ]*//')\n}\n</code></pre>"},{"location":"mastery/advanced_shell/#why-advanced-shell-matters-for-platform-work","title":"Why Advanced Shell Matters for Platform Work","text":"<p>SREs often work with irregular data and complex APIs. Standard tools might get you 90% of the way, but that last 10% requires custom logic.</p>"},{"location":"mastery/advanced_shell/#common-scenarios","title":"Common Scenarios","text":"Context-Aware Kubernetes Parsing Complex API Responses Bulk Operations <p>Instead of constantly typing the namespace, create a function that handles it: Scoped Kubectl<pre><code>kn() {\n  local ns=$1\n  shift\n  kubectl -n \"$ns\" \"$@\"\n}\n# Usage: kn production get pods\n</code></pre></p> <p>Build functions that wrap <code>curl</code> and <code>jq</code> for your most common internal APIs: Internal API Helper<pre><code>get_user() {\n  curl -s \"https://api.internal/users/$1\" | jq -r '.email'\n}\n</code></pre></p> <p>Use <code>xargs</code> and loops for operations that aren't natively supported by your tools: Cleanup Old Branches<pre><code>git branch --merged | grep -v \"\\*\" | xargs -n 1 git branch -d\n</code></pre></p>"},{"location":"mastery/advanced_shell/#logic-and-flow-control-in-the-shell","title":"Logic and Flow Control in the Shell","text":"<p>The shell is a full programming language. Understanding its logic allows you to build robust automation.</p> Robust Scripting Pattern<pre><code>#!/bin/bash\nset -euo pipefail  # (1)!\n\nTARGET=${1:-\"default_value\"}  # (2)!\n\nif [[ -z \"$TARGET\" ]]; then\n  echo \"Error: Target is required\"\n  exit 1\nfi\n\nmain() {\n  echo \"Processing $TARGET...\"\n  # ... your logic here ...\n}\n\nmain \"$@\"\n</code></pre> <ol> <li>Strict Mode: Exit on error, unset variables, and pipe failures.</li> <li>Parameter Expansion: Set a default value if the first argument is missing.</li> </ol>"},{"location":"mastery/advanced_shell/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Arguments in Aliases <p>Why can't you use an argument in the middle of an alias (e.g., <code>alias mygrep=\"grep $1 config.txt\"</code>)?</p> Answer <p>Aliases are simple text replacements. When you run <code>mygrep pattern</code>, the shell expands it to <code>grep $1 config.txt pattern</code>. It doesn't know how to \"inject\" the argument into the <code>$1</code> position. This is why you must use Functions for anything involving arguments.</p> Practice Problem 2: Parameter Expansion <p>In the command <code>${VAR:-\"tmp\"}</code>, what happens if <code>$VAR</code> is not set?</p> Answer <p>The shell will use the string <code>\"tmp\"</code> as the value. This is a very common pattern in SRE scripts to provide sensible defaults for environment variables or script arguments.</p>"},{"location":"mastery/advanced_shell/#key-takeaways","title":"Key Takeaways","text":"Feature Syntax Best Used For Alias <code>alias name='cmd'</code> Shorthand for simple commands Function <code>name() { ... }</code> Complex logic and arguments Default Value <code>${VAR:-default}</code> Handling missing inputs Strict Mode <code>set -euo pipefail</code> Writing safe, reliable scripts Silent Fail <code>command || true</code> When a non-zero exit is acceptable"},{"location":"mastery/advanced_shell/#further-reading","title":"Further Reading","text":""},{"location":"mastery/advanced_shell/#official-documentation","title":"Official Documentation","text":"<ul> <li>Bash Reference Manual - The definitive guide to Bash.</li> <li>Zsh Guide - Comprehensive documentation for Zsh features.</li> </ul>"},{"location":"mastery/advanced_shell/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>ShellCheck - A linter that finds bugs in your shell scripts.</li> <li>ExplainShell - Visual breakdown of complex command lines.</li> </ul>"},{"location":"mastery/advanced_shell/#deep-dives","title":"Deep Dives","text":"<ul> <li>Regular Expressions in Shell - Using regex with <code>sed</code> and <code>awk</code>.</li> <li>Process Management - Understanding signals, subshells, and job control.</li> </ul>"},{"location":"mastery/automation_patterns/","title":"Automation Patterns: Makefiles and Beyond","text":"<p>You're tired of typing the same five commands every time you deploy a service. You have a README with a \"Getting Started\" section that is already out of date. You're copy-pasting complex <code>docker run</code> commands from a Slack message. This is why we automate.</p> <p>In platform engineering, automation isn't just about saving time; it's about reducing variance. When a task is automated, it's performed the same way every time, regardless of who is running it or how much sleep they had.</p>"},{"location":"mastery/automation_patterns/#the-makefile-the-universal-run-button","title":"The Makefile: The Universal \"Run Button\"","text":"<p><code>make</code> is a build automation tool from the 1970s that remains one of the most powerful tools in an SRE's toolkit. It provides a simple, standard interface for running complex tasks.</p> Example Makefile<pre><code>.PHONY: test build deploy  # (1)!\n\ntest:\n    pytest tests/  # (2)!\n\nbuild:\n    docker build -t my-service:latest .\n\ndeploy: build\n    kubectl apply -f k8s/\n</code></pre> <ol> <li>Tells <code>make</code> that these are not actual files on disk.</li> <li>Commands must be indented with a Tab, not spaces.</li> </ol>"},{"location":"mastery/automation_patterns/#why-makefiles","title":"Why Makefiles?","text":"<ul> <li> <p> Standard Interface</p> <p>Why it matters: New team members don't need to know how to test or build. They just run <code>make test</code> or <code>make build</code>.</p> </li> <li> <p> Dependency Management</p> <p>Why it matters: <code>make</code> knows that you shouldn't <code>deploy</code> until you have successfully <code>built</code>.</p> </li> <li> <p> Language Agnostic</p> <p>Why it matters: One Makefile can handle Python, Go, Terraform, and Shell scripts in a single project.</p> </li> </ul>"},{"location":"mastery/automation_patterns/#advanced-automation-patterns","title":"Advanced Automation Patterns","text":""},{"location":"mastery/automation_patterns/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Don't wait for CI to catch a linting error. Use <code>pre-commit</code> to run checks locally every time you run <code>git commit</code>.</p> .pre-commit-config.yaml<pre><code>repos:\n-   repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.4.0\n    hooks:\n    -   id: trailing-whitespace\n    -   id: end-of-file-fixer\n-   repo: https://github.com/charliermarsh/ruff-pre-commit\n    rev: v0.0.272\n    hooks:\n    -   id: ruff\n</code></pre>"},{"location":"mastery/automation_patterns/#task-runners-taskfile","title":"Task Runners (Taskfile)","text":"<p>While <code>make</code> is great, some teams prefer <code>Task</code> (written in Go), which uses YAML and handles variables more gracefully.</p> Taskfile.yml<pre><code>version: '3'\n\ntasks:\n  build:\n    cmds:\n      - go build -v main.go\n\n  test:\n    cmds:\n      - go test ./...\n</code></pre>"},{"location":"mastery/automation_patterns/#why-this-matters-for-platform-work","title":"Why This Matters for Platform Work","text":"<p>For SREs, automation patterns are about Codifying Knowledge. A Makefile is a living document of how a project is built, tested, and deployed. It moves documentation from a static Wiki into an executable file.</p>"},{"location":"mastery/automation_patterns/#common-scenarios","title":"Common Scenarios","text":"One-Click Environment Setup Security Linting Automated Formatting <p>Create a <code>make setup</code> target that installs dependencies, configures local environment variables, and spins up a local database via Docker Compose.</p> <p>Add <code>tfsec</code> or <code>checkov</code> to your Makefile to ensure every Terraform change is audited for security vulnerabilities before it ever reaches a PR.</p> <p>Don't argue about indentation in code reviews. Add <code>black</code>, <code>ruff</code>, or <code>terraform fmt</code> to a <code>make format</code> target and make it a prerequisite for your build.</p>"},{"location":"mastery/automation_patterns/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Make Prerequisites <p>In the Makefile example above, what happens when you run <code>make deploy</code>?</p> Answer <p><code>make</code> sees that <code>deploy</code> depends on <code>build</code>. It will run the <code>build</code> target first. If the <code>docker build</code> command fails (returns a non-zero exit code), <code>make</code> will stop immediately and will not attempt to run the <code>kubectl apply</code> command.</p> Practice Problem 2: PHONY Targets <p>Why do we need the <code>.PHONY</code> declaration at the top of a Makefile?</p> Answer <p>By default, <code>make</code> thinks its targets are files. If you have a target named <code>test</code> and a folder named <code>test</code> in your directory, <code>make</code> will see the folder and think the \"file\" is already up to date, so it won't run your commands. <code>.PHONY</code> tells <code>make</code> to ignore the filesystem and always run the commands for that target.</p>"},{"location":"mastery/automation_patterns/#key-takeaways","title":"Key Takeaways","text":"Pattern Tool Best Used For Standard Interface <code>make</code> Unifying commands across different languages Local Quality <code>pre-commit</code> Catching errors before they are committed Modern Task Running <code>go-task</code> Complex workflows needing YAML/Variables CI Consistency GitHub Actions Ensuring the same automation runs in the cloud"},{"location":"mastery/automation_patterns/#further-reading","title":"Further Reading","text":""},{"location":"mastery/automation_patterns/#official-documentation","title":"Official Documentation","text":"<ul> <li>GNU Make Manual - The definitive (and very dry) guide to <code>make</code>.</li> <li>Pre-commit.com - Documentation for the pre-commit framework.</li> </ul>"},{"location":"mastery/automation_patterns/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Just - A modern command runner with a cleaner syntax than <code>make</code>.</li> <li>Mage - A make-like build tool using Go.</li> </ul>"},{"location":"mastery/automation_patterns/#deep-dives","title":"Deep Dives","text":"<ul> <li>Idempotency in Automation - Why running the same automation twice should be safe.</li> <li>DAGs in Build Systems - How <code>make</code> calculates the order of operations.</li> </ul>"},{"location":"mastery/git_internals/","title":"Git Internals: Blobs, Trees, and Commits","text":"<p>Most developers use Git every day, but few understand how it works under the hood. We think of Git as storing \"changes\" (diffs), but that is a lie.</p> <p>Git is actually a Content-Addressable Filesystem. It is a key-value database where the \"Key\" is the SHA-1 hash of the data, and the \"Value\" is the data itself.</p>"},{"location":"mastery/git_internals/#the-three-objects","title":"The Three Objects","text":"<p>Git is built on three fundamental objects:</p>"},{"location":"mastery/git_internals/#1-the-blob-binary-large-object","title":"1. The Blob (Binary Large Object)","text":"<p>A Blob stores the content of a file. It does not store the filename, the timestamp, or who wrote it. It is just the raw data.</p> <p>If you have two files (<code>a.txt</code> and <code>b.txt</code>) that both contain the text \"Hello World\", Git only stores one Blob. This is deduplication at the content level.</p>"},{"location":"mastery/git_internals/#2-the-tree","title":"2. The Tree","text":"<p>A Tree stores the directory structure. It maps filenames to Blobs (or other Trees).</p> <p>A Tree looks like this: <pre><code>100644 blob a906cb2...   README.md\n100644 blob 2e56a7f...   main.py\n040000 tree 92b8d23...   src/\n</code></pre></p>"},{"location":"mastery/git_internals/#3-the-commit","title":"3. The Commit","text":"<p>A Commit is a wrapper around a Tree. It adds the \"human\" context: -   Author: Who made it? -   Date: When? -   Message: Why? -   Parent: What came before this?</p>"},{"location":"mastery/git_internals/#the-dag-directed-acyclic-graph","title":"The DAG (Directed Acyclic Graph)","text":"<p>Because every commit points to its parent, a history of commits forms a chain. Because branches can split and merge, this chain forms a Graph.</p> <ul> <li>Directed: Time flows forward (Child -&gt; Parent).</li> <li>Acyclic: You can't loop back in time.</li> </ul>"},{"location":"mastery/git_internals/#visualizing-the-structure","title":"Visualizing the Structure","text":"<pre><code>graph TD\n    Commit[Commit 3a1b2c] --&gt; Tree[Tree 8f9e0d]\n    Commit --&gt; Parent[Parent Commit 1z2y3x]\n\n    Tree --&gt; Blob1[Blob: main.py]\n    Tree --&gt; Blob2[Blob: README.md]</code></pre>"},{"location":"mastery/git_internals/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Deduplication <p>You create a file <code>test.txt</code> with the content \"Hello\". You commit it. You create a new file <code>copy.txt</code> with the content \"Hello\". You commit it.</p> <p>How many Blob objects does Git store in the <code>.git</code> folder?</p> Solution <p>One.</p> <p>Since both files have the exact same content (\"Hello\"), they hash to the same SHA-1 value. Git stores that blob once. The two different filenames are stored in the Tree object, pointing to the same Blob hash.</p> Practice Problem 2: The Hash <p>Why does changing a single character in a file change the Commit ID?</p> Solution <ol> <li>Changing content changes the Blob Hash.</li> <li>Changing the Blob Hash changes the Tree Hash (because the Tree lists the Blob's hash).</li> <li>Changing the Tree Hash changes the Commit Hash (because the Commit points to the Tree).</li> </ol> <p>This \"Avalanche Effect\" ensures cryptographic integrity. You cannot alter history without changing every ID that comes after it.</p>"},{"location":"mastery/git_internals/#key-takeaways","title":"Key Takeaways","text":"Object Stores Blob File Content. Tree Filenames and Directory Structure. Commit History and Metadata. <p>Understanding that Git is just a graph of hashed objects demystifies complex operations. A \"Branch\" is just a sticky note pointing to a specific commit. A \"Merge\" is just creating a new commit with two parents. It's all just pointers.</p>"},{"location":"mastery/github_actions_sre/","title":"GitHub Actions for SREs: Beyond CI","text":"<p>Most developers use GitHub Actions to run tests and build Docker images. But for an SRE, Actions are programmable infrastructure. You can use them to automate incident response, rotate secrets, audit cloud resource usage, and manage your \"ops\" toil without ever running a dedicated cron server.</p>"},{"location":"mastery/github_actions_sre/#why-github-actions-for-platform-work","title":"Why GitHub Actions for Platform Work?","text":"<ul> <li> <p> No Servers to Manage</p> <p>Why it matters: Stop managing Jenkins or cron boxes. GitHub provides the compute, the logs, and the secrets management.</p> </li> <li> <p> Identity Federation</p> <p>Why it matters: Use OIDC (OpenID Connect) to allow Actions to talk to AWS, Azure, or GCP without long-lived access keys.</p> </li> <li> <p> Scheduled Operations</p> <p>Why it matters: Use <code>schedule: - cron: '...'</code> for recurring audits, cleanup tasks, and status checks.</p> </li> </ul>"},{"location":"mastery/github_actions_sre/#quick-start-the-sre-automation-template","title":"Quick Start: The SRE Automation Template","text":"<p>Here is a robust starting point for an Action that performs a platform task (like checking for unencrypted S3 buckets).</p> .github/workflows/s3-audit.yml<pre><code>name: S3 Security Audit\non:\n  schedule:\n    - cron: '0 0 * * *' # Run daily at midnight\n  workflow_dispatch:     # Allow manual trigger\n\njobs:\n  audit:\n    runs-on: ubuntu-latest\n    permissions:\n      id-token: write    # Required for OIDC\n      contents: read\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v3\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v2\n        with:\n          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}\n          aws-region: us-east-1\n\n      - name: Run Audit Script\n        run: |\n          ./scripts/check-s3-encryption.sh\n</code></pre>"},{"location":"mastery/github_actions_sre/#why-this-matters-for-platform-work","title":"Why This Matters for Platform Work","text":"<p>Automating your repetitive tasks in GitHub Actions provides a transparent audit trail. Anyone on the team can see when a task ran, what the output was, and how the logic is defined in code.</p>"},{"location":"mastery/github_actions_sre/#common-scenarios","title":"Common Scenarios","text":"Secret Rotation:material-\u6383\u9664: Environment Cleanup Auto-Remediation <p>Automate the rotation of API keys or IAM users. - Action triggers every 30 days. - Script generates a new key, updates the target system, and updates GitHub Secrets via the API. - Notify the team via Slack if it fails.</p> <p>Automatically delete \"dev\" environments that haven't been touched in 7 days. - Action runs every morning. - Uses <code>gh api</code> or cloud SDKs to find idle resources. - Sends a warning 24 hours before deletion.</p> <p>Trigger a workflow via a webhook from your monitoring system (like PagerDuty or Prometheus). - If a specific service is stuck, the Action can restart it or clear a cache. - This \"self-healing\" reduces on-call fatigue.</p>"},{"location":"mastery/github_actions_sre/#best-practices-for-sre-workflows","title":"Best Practices for SRE Workflows","text":"<ol> <li>Use OIDC: Never store <code>AWS_ACCESS_KEY_ID</code> in secrets. Use OIDC for short-lived, identity-based access.</li> <li>Pin Versions: Use <code>@v3</code> or specific SHAs for actions. Don't use <code>@master</code>.</li> <li>Concurrency Control: Use <code>concurrency</code> groups to prevent two \"deploy\" or \"cleanup\" jobs from running at the same time and conflicting.</li> <li>Least Privilege: Give the <code>GITHUB_TOKEN</code> only the permissions it needs (e.g., <code>contents: read</code>, <code>pull-requests: write</code>).</li> </ol>"},{"location":"mastery/github_actions_sre/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Manual Triggers <p>How do you make a GitHub Action available to be run manually from the GitHub UI with a custom input field?</p> Answer <p>Use the <code>workflow_dispatch</code> trigger: <pre><code>on:\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: 'Target Environment'\n        required: true\n        default: 'staging'\n</code></pre></p> Practice Problem 2: Security <p>Why is it safer to use <code>permissions: { id-token: write }</code> and OIDC instead of a long-lived API key stored in <code>secrets.AWS_ACCESS_KEY_ID</code>?</p> Answer <p>OIDC provides short-lived, scoped credentials. There is no \"secret\" to leak or rotate. If an attacker gains access to your Action, the credentials expire in minutes. If someone steals your <code>AWS_ACCESS_KEY_ID</code>, they have permanent access until you manually rotate the key.</p>"},{"location":"mastery/github_actions_sre/#key-takeaways","title":"Key Takeaways","text":"Feature Purpose <code>workflow_dispatch</code> Allow manual runs via UI or API <code>schedule</code> Cron-like recurring tasks <code>OIDC</code> Secure, keyless cloud access <code>concurrency</code> Prevent overlapping job runs <code>outputs</code> Pass data between jobs"},{"location":"mastery/github_actions_sre/#further-reading","title":"Further Reading","text":""},{"location":"mastery/github_actions_sre/#official-documentation","title":"Official Documentation","text":"<ul> <li>GitHub Actions Documentation - The comprehensive guide.</li> <li>Security Hardening for GitHub Actions - Essential reading for SREs.</li> </ul>"},{"location":"mastery/github_actions_sre/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Action-validator - Tool to validate your YAML syntax.</li> <li>Act - Run your GitHub Actions locally in Docker for faster testing.</li> </ul>"},{"location":"mastery/github_actions_sre/#deep-dives","title":"Deep Dives","text":"<ul> <li>Identity and Access Management - How OIDC and identity federation work.</li> <li>Event-Driven Systems - Understanding the webhook and trigger model of Actions.</li> </ul>"},{"location":"mastery/local_testing_docker/","title":"Local Testing with Docker and Podman","text":"<p>You've written a complex shell script or a Python automation tool. You're ready to test it, but you don't want to run it on your laptop and mess up your local files, and you definitely don't want to test it in production. This is why we use containers for local development.</p> <p>Docker and Podman allow you to create isolated, reproducible environments that mimic your production servers. For SREs, this is the ultimate \"sandbox\" for testing scripts, infrastructure changes, and automation before they ever touch real systems.</p>"},{"location":"mastery/local_testing_docker/#why-container-testing","title":"Why Container Testing?","text":"<ul> <li> <p> Isolation</p> <p>Why it matters: Run your \"destructive\" scripts safely. If a script runs <code>rm -rf /</code>, it only deletes files inside the container, not on your laptop.</p> </li> <li> <p> Reproducibility</p> <p>Why it matters: \"It works on my machine\" is no longer an excuse. If it works in the container, it will work on the server running the same image.</p> </li> <li> <p> Multi-service Testing</p> <p>Why it matters: Use Docker Compose to spin up a database, a cache, and your script all at once to test their interactions.</p> </li> </ul>"},{"location":"mastery/local_testing_docker/#quick-start-the-sre-sandbox","title":"Quick Start: The SRE Sandbox","text":"<p>Need a clean Ubuntu environment to test a script?</p> Start a Sandbox<pre><code># Start a container and enter its shell\ndocker run --rm -it -v $(pwd):/work -w /work ubuntu:22.04 bash\n\n# -it: Interactive terminal\n# --rm: Delete the container when you exit\n# -v: Mount your current directory into /work\n# -w: Start in the /work directory\n</code></pre>"},{"location":"mastery/local_testing_docker/#why-this-matters-for-platform-work","title":"Why This Matters for Platform Work","text":"<p>Platform engineers often write code that interacts with the OS, the network, or other services. Testing these interactions requires an environment that is \"clean\" yet \"realistic.\"</p>"},{"location":"mastery/local_testing_docker/#common-scenarios","title":"Common Scenarios","text":"Testing Shell Scripts Local DB Migrations Mocking Cloud APIs <p>Testing a script that installs packages and modifies <code>/etc</code>? - Use a <code>Dockerfile</code> to create a mirror of your production OS. - Run the script inside the container. - Check the exit code and file state.</p> <p>Testing a database schema change? - Use <code>docker-compose</code> to start the exact version of Postgres/MySQL you use in production. - Run your migration script against the local container. - If it fails, just <code>docker-compose down -v</code> and start over with a fresh DB.</p> <p>Use tools like LocalStack inside Docker to simulate AWS services locally. Test your S3 upload script or your SQS consumer without spending a cent on cloud costs.</p>"},{"location":"mastery/local_testing_docker/#podman-the-daemonless-alternative","title":"Podman: The Daemonless Alternative","text":"<p>Many SREs prefer Podman over Docker. - Rootless: It doesn't require <code>sudo</code> to run containers, making it more secure. - No Daemon: It doesn't have a background process that can fail; it's a simple fork/exec model. - Compatible: Most <code>docker</code> commands can be aliased to <code>podman</code> (e.g., <code>alias docker=podman</code>).</p>"},{"location":"mastery/local_testing_docker/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Volumes and Persistence <p>You are running a script in a container that writes logs to <code>/var/log/myapp.log</code>. When the container exits, the log file is gone. How do you make the logs persist on your local laptop?</p> Answer <p>Use a Volume Mount (<code>-v</code>).  <pre><code>docker run -v $(pwd)/logs:/var/log ubuntu ...\n</code></pre> This maps your local <code>./logs</code> directory to the container's <code>/var/log</code>. Anything the script writes there will be saved on your laptop.</p> Practice Problem 2: Networking <p>You have two containers: <code>app</code> and <code>db</code>. How do they talk to each other if they are in separate containers?</p> Answer <p>Use a Docker Network or Docker Compose. In a Compose file, services can reach each other by their service name (e.g., the app can connect to <code>postgres://db:5432</code>).</p>"},{"location":"mastery/local_testing_docker/#key-takeaways","title":"Key Takeaways","text":"Action Command Run &amp; Enter <code>docker run -it &lt;image&gt; bash</code> Mount Directory <code>-v &lt;local&gt;:&lt;remote&gt;</code> Clean Up <code>--rm</code> Check Logs <code>docker logs &lt;container_id&gt;</code> Multi-container <code>docker-compose up</code>"},{"location":"mastery/local_testing_docker/#further-reading","title":"Further Reading","text":""},{"location":"mastery/local_testing_docker/#official-documentation","title":"Official Documentation","text":"<ul> <li>Docker Get Started - Official introductory guide.</li> <li>Podman Documentation - For those moving to rootless containers.</li> </ul>"},{"location":"mastery/local_testing_docker/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>LocalStack - Fully functional local AWS cloud stack.</li> <li>Kind (Kubernetes in Docker) - Run a full K8s cluster inside Docker.</li> </ul>"},{"location":"mastery/local_testing_docker/#deep-dives","title":"Deep Dives","text":"<ul> <li>Namespace and Cgroups - The Linux kernels features that make containers possible.</li> <li>Immutable Infrastructure - Why containers are the foundation of modern deployment patterns.</li> </ul>"},{"location":"mastery/makefiles/","title":"Makefiles","text":"<p>In the modern world of fancy IDEs and complex CI/CD pipelines, the humble Makefile remains one of the most powerful tools in a developer's workshop.</p> <p>Invented in 1976, <code>make</code> is a build automation tool. It answers one simple question: \"Which files need to be updated?\"</p>"},{"location":"mastery/makefiles/#the-core-concept-dependency","title":"The Core Concept: Dependency","text":"<p><code>make</code> doesn't just run scripts; it checks timestamps.</p> <ul> <li>If <code>main.o</code> is older than <code>main.c</code>, then <code>main.c</code> must have changed.</li> <li>Therefore, we must rebuild <code>main.o</code>.</li> <li>If <code>main.c</code> hasn't changed, do nothing.</li> </ul> <p>This \"Lazy Evaluation\" saves massive amounts of time in large projects.</p>"},{"location":"mastery/makefiles/#the-syntax","title":"The Syntax","text":"<p>A Makefile is composed of Rules.</p> <pre><code>target: dependencies\n    command\n</code></pre> <p>Important: The indentation MUST be a Tab character, not spaces.</p>"},{"location":"mastery/makefiles/#example","title":"Example","text":"<pre><code># The final executable depends on the object file\napp: main.o\n    gcc -o app main.o\n\n# The object file depends on the source code\nmain.o: main.c\n    gcc -c main.c\n\n# A \"Phony\" target to clean up\nclean:\n    rm *.o app\n</code></pre>"},{"location":"mastery/makefiles/#how-it-works","title":"How it Works","text":"<ol> <li>You run <code>make app</code>.</li> <li>Make looks at <code>app</code>. It needs <code>main.o</code>.</li> <li>Make looks at <code>main.o</code>. It needs <code>main.c</code>.</li> <li>Make checks the timestamps.<ul> <li>If <code>main.c</code> is newer than <code>main.o</code>, it runs the command <code>gcc -c main.c</code>.</li> <li>Then, it runs the command for <code>app</code>.</li> </ul> </li> </ol>"},{"location":"mastery/makefiles/#variables-and-phony-targets","title":"Variables and Phony Targets","text":"<p>To make Makefiles readable, we use variables.</p> <pre><code>CC = gcc\nCFLAGS = -Wall -g\n\nbuild: main.c\n    $(CC) $(CFLAGS) -o app main.c\n</code></pre> <p>Phony Targets are commands that don't produce a file (like <code>clean</code>, <code>test</code>, or <code>deploy</code>). We mark them so <code>make</code> doesn't get confused if a file named \"clean\" accidentally exists.</p> <pre><code>.PHONY: clean test\n\nclean:\n    rm -rf build/\n</code></pre>"},{"location":"mastery/makefiles/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: The Infinite Loop <p>What happens if you have a circular dependency? A: B B: A</p> Solution <p>Make will complain.</p> <p><code>make</code> detects the cycle and drops a dependency to break the loop, usually printing a warning: <code>make: Circular A &lt;- B dependency dropped.</code></p> Practice Problem 2: Always Run <p>If you want a command to run every single time you type <code>make</code>, regardless of file changes, what should you do?</p> Solution <p>Make it a Phony Target. </p> <p>Since a Phony Target (like <code>print-date</code>) doesn't correspond to a file, <code>make</code> assumes the \"file\" is always missing and therefore always runs the command to \"build\" it.</p>"},{"location":"mastery/makefiles/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Target: The file you want to create.</li> <li>Dependency: The files the target relies on.</li> <li>Command: The script to build the target.</li> <li>Lazy: Only rebuilds what changed.</li> </ul> <p>Makefiles are the universal adapter of the software world. Whether you are compiling C, generating a static website, or deploying to Kubernetes, a <code>Makefile</code> provides a standard, documented entry point for anyone joining your project.</p>"},{"location":"mastery/neovim_full_setup/","title":"NeoVim Full Setup: The Terminal IDE","text":"<p>You've learned basic Vim - you can move with <code>h/j/k/l</code> and edit files over SSH. But you're tired of switching back to VS Code for \"real\" work. This is why you graduate to NeoVim.</p> <p>NeoVim is a modern fork of Vim designed for extensibility. By leveraging the Lua programming language and a massive ecosystem of plugins, you can transform your terminal editor into a high-performance IDE that rivals VS Code while remaining entirely keyboard-driven.</p>"},{"location":"mastery/neovim_full_setup/#why-neovim","title":"Why NeoVim?","text":"<ul> <li> <p> The Power of Composability</p> <p>Why it matters: Vim's \"grammar\" (<code>action</code> + <code>motion</code>) allows you to perform complex edits with minimal keystrokes. <code>di\"</code> deletes everything inside quotes. <code>cap</code> changes an entire paragraph.</p> </li> <li> <p> LSP (Language Server Protocol)</p> <p>Why it matters: Get the same autocomplete, go-to-definition, and refactoring tools as VS Code, but inside your terminal.</p> </li> <li> <p> Incredible Speed</p> <p>Why it matters: NeoVim starts instantly and stays responsive even in massive repositories where traditional IDEs struggle.</p> </li> </ul>"},{"location":"mastery/neovim_full_setup/#starting-point-the-distribution-approach","title":"Starting Point: The \"Distribution\" Approach","text":"<p>Configuring NeoVim from scratch can take weeks. For most SREs, we recommend starting with a Distribution\u2014a pre-configured setup with sensible defaults.</p>  LazyVim Kickstart.nvim AstroNvim <p>Best for: SREs who want a \"it just works\" experience. - Highly modular and fast. - Excellent defaults for Python, YAML, and Docker. - Uses <code>Lazy.nvim</code> for lightning-fast plugin management.</p> <p>Best for: Those who want to learn how NeoVim actually works. - A single-file configuration that you can read and understand. - Teaches you the basics of Lua and LSP setup.</p> <p>Best for: Users who want a feature-rich, \"batteries-included\" experience. - Extensive UI components and dashboard. - Great for those used to full-featured IDEs.</p>"},{"location":"mastery/neovim_full_setup/#essential-plugin-categories-for-platform-work","title":"Essential Plugin Categories for Platform Work","text":"<p>To replace your IDE, you need these four core capabilities:</p> <ol> <li>LSP (Language Server Protocol): Use <code>mason.nvim</code> to install servers for Python (Pyright), YAML (yamlls), and Terraform.</li> <li>Telescope: Fuzzy find everything\u2014files, text in files, git commits, and even LSP symbols.</li> <li>Treesitter: Advanced syntax highlighting that \"understands\" the code structure, making logs and configs much easier to read.</li> <li>Neo-tree / nvim-tree: A sidebar file explorer for when you need to visualize the project structure.</li> </ol>"},{"location":"mastery/neovim_full_setup/#quick-start-the-lazyvim-install","title":"Quick Start: The LazyVim Install","text":"<p>If you have Git and NeoVim 0.9+ installed:</p> Install LazyVim<pre><code># Backup your current config\nmv ~/.config/nvim ~/.config/nvim.bak\n\n# Clone the starter template\ngit clone https://github.com/LazyVim/starter ~/.config/nvim\n\n# Remove the .git folder so you can start your own history\nrm -rf ~/.config/nvim/.git\n\n# Start NeoVim\nnvim\n</code></pre>"},{"location":"mastery/neovim_full_setup/#why-this-matters-for-platform-work","title":"Why This Matters for Platform Work","text":"<p>As an SRE, you are often editing code on remote servers where a GUI isn't an option. A full NeoVim setup allows you to maintain 100% of your productivity in those environments. You no longer have to compromise between \"terminal speed\" and \"IDE power.\"</p>"},{"location":"mastery/neovim_full_setup/#common-scenarios","title":"Common Scenarios","text":"Large Repo Navigation Integrated Git (Lazygit) Real-time Linting <p>In a massive Terraform repo, use <code>Telescope</code> to jump to a module definition in milliseconds: - <code>Space</code> + <code>s</code> + <code>s</code>: Search for a symbol (like a module or variable name). - <code>Space</code> + <code>f</code> + <code>f</code>: Find file by name.</p> <p>LazyVim integrates beautifully with <code>lazygit</code>. - <code>Space</code> + <code>g</code> + <code>g</code>: Open a full-screen, interactive Git interface without leaving the editor.</p> <p>Get immediate feedback on your Kubernetes YAML indentation or Python syntax errors as you type. No more <code>kubectl apply</code> failures because of a missing space.</p>"},{"location":"mastery/neovim_full_setup/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: The Leader Key <p>In most NeoVim configs (especially LazyVim), what is the \"Leader\" key and why is it used?</p> Answer <p>The Leader key (usually <code>Space</code> or <code>`) is a prefix used to trigger custom commands without conflicting with Vim's built-in motions. For example,</code>Leader<code>+</code>f<code>+</code>f` is a common shortcut for \"Find Files.\" It's the gateway to your custom IDE features.</p> Practice Problem 2: LSP vs Syntax Highlighting <p>What is the difference between <code>Treesitter</code> and a <code>Language Server (LSP)</code>?</p> Answer <p>Treesitter is for high-performance syntax highlighting and text objects. it builds a \"syntax tree\" of the file to understand its structure.  LSP provides semantic intelligence\u2014it knows if a variable is defined, what its type is, and how to jump to its source. Treesitter makes the code look right; LSP makes it \"smart.\"</p>"},{"location":"mastery/neovim_full_setup/#key-takeaways","title":"Key Takeaways","text":"Tool Purpose Lua The configuration language for NeoVim Lazy.nvim Fast, modern plugin manager LSP Intelligence (Autocomplete, Definitions) Treesitter Advanced Highlighting Telescope Fuzzy Finding everything"},{"location":"mastery/neovim_full_setup/#further-reading","title":"Further Reading","text":""},{"location":"mastery/neovim_full_setup/#official-documentation","title":"Official Documentation","text":"<ul> <li>NeoVim Documentation - The official manual.</li> <li>LazyVim Docs - Comprehensive guide to the LazyVim distribution.</li> </ul>"},{"location":"mastery/neovim_full_setup/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Mason.nvim - Portable package manager for LSPs, DAP servers, linters, and formatters.</li> <li>Tree-sitter - The incremental parsing system.</li> </ul>"},{"location":"mastery/neovim_full_setup/#deep-dives","title":"Deep Dives","text":"<ul> <li>Modal Editing Philosophy - How motions and actions form a language for editing.</li> <li>ASTs and Parsing - How Treesitter and LSPs understand your code.</li> </ul>"},{"location":"mastery/semantic_versioning/","title":"Semantic Versioning for Internal Tools","text":"<p>You've updated a common script used by your team, and now half of your CI pipelines are failing. You thought the change was \"small,\" but it broke a downstream dependency you didn't know existed. This is why we use Semantic Versioning (SemVer).</p> <p>Semantic Versioning (SemVer) is a simple set of rules and requirements that dictate how version numbers are assigned and incremented. For SREs building internal tools, modules, and APIs, SemVer provides a contract that tells your users (and your automation) what to expect when you release an update.</p>"},{"location":"mastery/semantic_versioning/#the-semver-structure","title":"The SemVer Structure","text":"<p>A version number follows the format <code>MAJOR.MINOR.PATCH</code>.</p> <pre><code>graph LR\n    V[1.2.3] --&gt; Major[1: MAJOR]\n    V --&gt; Minor[2: MINOR]\n    V --&gt; Patch[3: PATCH]\n\n    Major -- \"Breaking Changes\" --&gt; Impact1[High]\n    Minor -- \"New Features\" --&gt; Impact2[Medium]\n    Patch -- \"Bug Fixes\" --&gt; Impact3[Low]</code></pre> <ol> <li>MAJOR: Incremented when you make incompatible API changes.</li> <li>MINOR: Incremented when you add functionality in a backwards compatible manner.</li> <li>PATCH: Incremented when you make backwards compatible bug fixes.</li> </ol>"},{"location":"mastery/semantic_versioning/#quick-start-when-to-increment","title":"Quick Start: When to Increment","text":"Change Type Version Increment Example Bug Fix <code>PATCH</code> (1.0.0 \u2192 1.0.1) Fixed a typo in a help message. New Feature <code>MINOR</code> (1.0.1 \u2192 1.1.0) Added a new flag to your CLI tool. Breaking Change <code>MAJOR</code> (1.1.0 \u2192 2.0.0) Renamed a required flag or changed output format."},{"location":"mastery/semantic_versioning/#why-semver-matters-for-platform-work","title":"Why SemVer Matters for Platform Work","text":"<p>In Platform Engineering, your \"users\" are often other automated systems. If your <code>terraform-module-vpc</code> v1.0.0 is used by 50 projects, a breaking change without a MAJOR version bump will cause 50 broken pipelines.</p>"},{"location":"mastery/semantic_versioning/#common-scenarios","title":"Common Scenarios","text":"Terraform Modules Docker Image Tagging Automated Releases <p>Always use SemVer for your internal Terraform modules. - <code>v1.x.x</code>: Users can safely update. - <code>v2.x.x</code>: Users must manually check for breaking changes (like a removed variable). - In your code: <code>version = \"~&gt; 1.0\"</code> allows PATCH/MINOR updates but stops at 2.0.</p> <p>Stop using <code>:latest</code>. It's non-deterministic and dangerous. - Tag images with their full SemVer: <code>my-service:1.2.3</code>. - Provide \"moving\" tags for convenience: <code>my-service:1</code> (points to latest 1.x.x) and <code>my-service:1.2</code> (points to latest 1.2.x).</p> <p>Use tools like <code>semantic-release</code> or <code>conventional-commits</code> to automate your versioning. - If your commit message starts with <code>feat:</code>, the tool bumps the MINOR version. - If it starts with <code>fix:</code>, it bumps the PATCH version. - If the body contains <code>BREAKING CHANGE:</code>, it bumps the MAJOR version.</p>"},{"location":"mastery/semantic_versioning/#core-versioning-patterns","title":"Core Versioning Patterns","text":"<ul> <li> <p> The 0.y.z Phase</p> <p>Why it matters: Initial development. Anything can change at any time. Do not rely on 0.x versions for production-critical systems.</p> </li> <li> <p> Backwards Compatibility</p> <p>Why it matters: If you can add a feature without breaking existing users, always prefer a MINOR bump. It builds trust with your team.</p> </li> <li> <p> Pre-releases</p> <p>Why it matters: Use suffixes like <code>-alpha</code>, <code>-beta</code>, or <code>-rc</code> (Release Candidate) for testing new infrastructure changes before they go live.</p> </li> </ul>"},{"location":"mastery/semantic_versioning/#practice-problems","title":"Practice Problems","text":"Practice Problem 1: Increment Decision <p>You are updating a shared Python library used for incident response. You added a new function to calculate uptime, but didn't change any existing functions. What is the correct SemVer increment?</p> Answer <p>This is a MINOR increment (e.g., 1.2.3 \u2192 1.3.0). You added functionality in a backwards-compatible way.</p> Practice Problem 2: Breaking Changes <p>You are refactoring a shell script. You realized that a flag named <code>--verbose</code> was spelled incorrectly as <code>--verbos</code>. You fixed the spelling. Is this a PATCH or a MAJOR change?</p> Answer <p>Technically, this is a MAJOR change. Any existing automation that relies on the <code>--verbos</code> flag will now break. In the world of SemVer, \"correcting\" an API is still a breaking change if it breaks existing users.</p>"},{"location":"mastery/semantic_versioning/#key-takeaways","title":"Key Takeaways","text":"Rule Meaning Major Incompatible changes; user must take action. Minor New features; backwards compatible. Patch Fixes; backwards compatible. No <code>:latest</code> Be explicit with your versions in production. Contract A version number is a promise to your users."},{"location":"mastery/semantic_versioning/#further-reading","title":"Further Reading","text":""},{"location":"mastery/semantic_versioning/#official-documentation","title":"Official Documentation","text":"<ul> <li>SemVer.org - The full Semantic Versioning specification.</li> <li>Conventional Commits - A specification for adding human and machine readable meaning to commit messages.</li> </ul>"},{"location":"mastery/semantic_versioning/#related-tools-alternatives","title":"Related Tools &amp; Alternatives","text":"<ul> <li>Release-it - Interactive tool to automate SemVer releases.</li> <li>Standard Version - Automate versioning and CHANGELOG generation.</li> </ul>"},{"location":"mastery/semantic_versioning/#deep-dives","title":"Deep Dives","text":"<ul> <li>Dependency Management - How SemVer helps solve the \"dependency hell\" problem.</li> <li>API Design - Principles of building stable, versionable interfaces.</li> </ul>"}]}